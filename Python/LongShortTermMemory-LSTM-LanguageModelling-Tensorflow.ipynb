{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Applying Recurrent Neural Networks/LSTM for Language Modeling</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>The Objective</h2>\n",
    "Recurrent Networks are a specialized model to process sequential data by keeping track of the \"state\" or context. In this notebook, we go over a TensorFlow code snippet for creating a model focused on <b>Language Modelling</b> -- a very relevant task that is the cornerstone of many different linguistic problems such as <b>Speech Recognition, Machine Translation and Image Captioning</b>. For this, we will be using the Penn Treebank dataset, which is an often-used dataset for benchmarking Language Modelling models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on JupyerLab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2>Table of Contents</h2>\n",
    "<ol>\n",
    "    <li><a href=\"#language_modelling\">What exactly is Language Modelling?</a></li>\n",
    "    <li><a href=\"#treebank_dataset\">The Penn Treebank dataset</a></li>\n",
    "    <li><a href=\"#word_embedding\">Word Embedding</a></li>\n",
    "    <li><a href=\"#building_lstm_model\">Building the LSTM model for Language Modeling</a></li>\n",
    "    <li><a href=\"#ltsm\">LTSM</a></li>\n",
    "</ol>\n",
    "<p></p>\n",
    "</div>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"language_modelling\"></a>\n",
    "<h2>What exactly is Language Modelling?</h2>\n",
    "Language Modelling, to put it simply, <b>is the task of assigning probabilities to sequences of words</b>. This means that, given a context of one or a sequence of words in the language the model was trained on, the model should provide the next most probable words or sequence of words that follows from the given sequence of words the sentence. Language Modelling is one of the most important tasks in Natural Language Processing.\n",
    "\n",
    "<img src=\"https://ibm.box.com/shared/static/1d1i5gub6wljby2vani2vzxp0xsph702.png\" width=\"1080\">\n",
    "<center><i>Example of a sentence being predicted</i></center>\n",
    "<br><br>\n",
    "In this example, one can see the predictions for the next word of a sentence, given the context \"This is an\". As you can see, this boils down to a sequential data analysis task -- you are given a word or a sequence of words (the input data), and, given the context (the state), you need to find out what is the next word (the prediction). This kind of analysis is very important for language-related tasks such as <b>Speech Recognition, Machine Translation, Image Captioning, Text Correction</b> and many other very relevant problems. \n",
    "\n",
    "<img src=\"https://ibm.box.com/shared/static/az39idf9ipfdpc5ugifpgxnydelhyf3i.png\" width=\"1080\">\n",
    "<center><i>The above example is a schema of an RNN in execution</i></center>\n",
    "<br><br>\n",
    "As the above image shows, Recurrent Network models fit this problem like a glove. Alongside LSTM and its capacity to maintain the model's state for over one thousand time steps, we have all the tools we need to undertake this problem. The goal for this notebook is to create a model that can reach <b>low levels of perplexity</b> on our desired dataset.\n",
    "\n",
    "For Language Modelling problems, <b>perplexity</b> is the way to gauge efficiency. **Perplexity is simply a measure of how well a probabilistic model is able to predict its sample.** A higher-level way to explain this would be saying that <b>**low perplexity means a higher degree of trust in the predictions the model makes**</b>. Therefore, **the lower perplexity is, the better.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The sequence of words forms the context and the most recent word is the input data. Using these two pieces of information, you need to output both a predicted word and a new context that contains the input word. Recurrent Neural Networks are a great fit for this type of problem. At the first time step, a recurrent net can receive a word as input along the initial contexts. It generates an output. The output word with a current sequence of words as the context will then be re-fed into the network in the second time step. A new word would be predicted and these steps are repeated until the sentence is complete.\n",
    "\n",
    "<img src=\"https://jupyterlab-0-labs-prod-jupyterlab-us-east-0.labs.cognitiveclass.ai/user/mathildeduvi/files/labs/LSTM01.png?_xsrf=MnwxOjB8MTA6MTcxNzQzNTEwOHw1Ol94c3JmfDEzMjpZbVJsTkdJM01HWTRORGsxTkRabE9EbGtOVGxpT0RZM04ySm1aVGMzTURnNk4ySmtNV1V4TW1Ga09XTXlabVF4WkRjeVl6azJNalprWlRNd1kyVTFZVEExWWpFNVpHRTBOelpsTVRaaU1qRTVObVprTVRVMlltTmtNalJrWlRaa1pnPT18ZjI0MWI2YTA1MWI3Y2RhNzg3ZjBmMjcwZjUxYTBjYWUxN2EwMWJjODU0NDc0Yjk1ZDU2ZWRiMjg4ODZiYmE0Ng\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"treebank_dataset\"></a>\n",
    "<h2>The Penn Treebank dataset</h2>\n",
    "Historically, datasets big enough for Natural Language Processing are hard to come by. This is in part due to the necessity of the sentences to be broken down and tagged with a certain degree of correctness -- or else the models trained on it won't be able to be correct at all. This means that we need a <b>large amount of data, annotated by or at least corrected by humans</b>. This is, of course, not an easy task at all.\n",
    "\n",
    "The Penn Treebank, or PTB for short, is a dataset maintained by the University of Pennsylvania. It is <i>huge</i> -- there are over <b>four million and eight hundred thousand</b> annotated words in it, all corrected by humans. It is composed of many different sources, from abstracts of Department of Energy papers to texts from the Library of America. Since it is verifiably correct and of such a huge size, the Penn Treebank is commonly used as a benchmark dataset for Language Modelling.\n",
    "\n",
    "The dataset is divided in different kinds of annotations, such as Piece-of-Speech, Syntactic and Semantic skeletons. For this example, we will simply use a sample of clean, non-annotated words (with the exception of one tag --<code>&lt;unk&gt;</code>\n",
    ", which is used for rare words such as uncommon proper nouns) for our model. This means that we just want to predict what the next words would be, not what they mean in context or their classes on a given sentence.\n",
    "\n",
    "<center>Example of text from the dataset we are going to use, <b>ptb.train</b></center>\n",
    "<br><br>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    <center>the percentage of lung cancer deaths among the workers at the west <code>&lt;unk&gt;</code> mass. paper factory appears to be the highest for any asbestos workers studied in western industrialized countries he said \n",
    " the plant which is owned by <code>&lt;unk&gt;</code> & <code>&lt;unk&gt;</code> co. was under contract with <code>&lt;unk&gt;</code> to make the cigarette filters \n",
    " the finding probably will support those who argue that the U.S. should regulate the class of asbestos including <code>&lt;unk&gt;</code> more <code>&lt;unk&gt;</code> than the common kind of asbestos <code>&lt;unk&gt;</code> found in most schools and other buildings dr. <code>&lt;unk&gt;</code> said</center>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"word_embedding\"></a>\n",
    "<h2>Word Embeddings</h2><br/>\n",
    "\n",
    "For better processing, in this example, we will make use of <a href=\"https://www.tensorflow.org/tutorials/word2vec/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0120ENSkillsNetwork954-2023-01-01\"><b>word embeddings</b></a>, **which is <b>a way of representing sentence structures or words as n-dimensional vectors (where n is a reasonably high number, such as 200 or 500) of real numbers</b>.** **Basically, we will assign each word a randomly-initialized vector, and input those into the network to be processed.** After a number of iterations, these vectors are expected to assume values that help the network to correctly predict what it needs to -- in our case, the probable next word in the sentence. This is shown to be a very effective task in Natural Language Processing, and is a commonplace practice.\n",
    "<br><br>\n",
    "<font size=\"4\"><strong>\n",
    "$$Vec(\"Example\") = [0.02, 0.00, 0.00, 0.92, 0.30, \\ldots]$$\n",
    "</strong></font>\n",
    "<br>\n",
    "**Word Embedding tends to group up similarly used words <i>reasonably</i> close together in the vectorial space.** For example, if we use T-SNE (a dimensional reduction visualization algorithm) to flatten the dimensions of our vectors into a 2-dimensional space and plot these words in a 2-dimensional space, we might see something like this:\n",
    "\n",
    "<img src=\"https://ibm.box.com/shared/static/bqhc5dg879gcoabzhxra1w8rkg3od1cu.png\" width=\"800\">\n",
    "<center><i>T-SNE Mockup with clusters marked for easier visualization</i></center>\n",
    "\n",
    "**As you can see, words that are frequently used together, in place of each other, or in the same places as them tend to be grouped together -- being closer together the higher they are correlated.** For example, \"None\" is pretty semantically close to \"Zero\", while a phrase that uses \"Italy\", you could probably also fit \"Germany\" in it, with little damage to the sentence structure. **The vectorial \"closeness\" for similar words like this is a great indicator of a well-built model.**\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In sum, a Word Embedding is an n-dimensional vector of real numbers for each word. The vector is typically large, for example 200 length. \n",
    "\n",
    "<img src=\"https://jupyterlab-0-labs-prod-jupyterlab-us-east-0.labs.cognitiveclass.ai/user/mathildeduvi/files/labs/LSTM02.png?_xsrf=MnwxOjB8MTA6MTcxNzQzNTEwOHw1Ol94c3JmfDEzMjpZbVJsTkdJM01HWTRORGsxTkRabE9EbGtOVGxpT0RZM04ySm1aVGMzTURnNk4ySmtNV1V4TW1Ga09XTXlabVF4WkRjeVl6azJNalprWlRNd1kyVTFZVEExWWpFNVpHRTBOelpsTVRaaU1qRTVObVprTVRVMlltTmtNalJrWlRaa1pnPT18ZjI0MWI2YTA1MWI3Y2RhNzg3ZjBmMjcwZjUxYTBjYWUxN2EwMWJjODU0NDc0Yjk1ZDU2ZWRiMjg4ODZiYmE0Ng\" width=\"600\">\n",
    "\n",
    "You can see what that might look like with the word *example* here. You think of Word Embedding as a type of encoding for text to numbers. Now, the question is how do we find the proper values for these vectors? \n",
    "\n",
    "**In our RNN model, the vectors also known as the matrix for the vocabulary are initialized randomly for all the words that we are going to use for training. Then, during the recurrent network's training, the vector values are updated based on the context into which the word is being inserted. So, words that are used in similar contexts end up with similar positions in the vector space. This can be visualized by utilizing a dimensionality reduction algorithm.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the RNN, if we visualize the words based on their embedding vectors, the words are grouped together, either because they're synonyms or they're used in similar places within a sentence. For example, the words *zero* and *none* are close semantically, so it's natural for them to be placed close together. While Italy and Germany aren't synonyms, they can be interchanged in several sentences without distorting the grammar.\n",
    "\n",
    "Now let's look back at the RNN that we have been using. Imagine that the input data is a batch with only one sequence of words. Think of it as a batch that includes one sentence only, **one that includes 20 words.** Assume that **the vocabulary size of the words is 10,000 words** and **the length of each embedding vector is 200.**\n",
    "\n",
    "We have to look up those 20 words in the randomly initialized embedding matrix and **then feed them into the first LSTM unit.** Please notice that **only one word in each time step is fed into the network and one word would be the output.** **But during 20 time steps, the output would be 20 words.** In our network, we have **two LSTM units with arbitrary hidden sizes of 256 and 128.** So the **output of the second LSTM unit** would be a matrix of size **20 by 128.** \n",
    "\n",
    "Now, **we need a Softmax layer to calculate the probability of the output words.** It squashes that 128 dimensional vector of real values to a **10,000 dimensional vector, which is a vocabulary size.**\n",
    "**This means that the output of the network at each time step as a probability vector of length 10,000. So the output word is the one with maximum probability value in the vector.**\n",
    "\n",
    "Now, we can **compare the sequence of 20 output words with the ground truth words.** Finally, **calculate the discrepancy as a quantitative value, so-called loss value and back propagate the errors into the network, and of course, we will not train the model using only one sequence. We will use a batch of sequences to train it and calculate the error.** So instead of feeding one sequence, we can feed the network in **many iterations, perhaps even a batch of 60 sentences for example.**\n",
    "\n",
    "Now, the key question to be asked is, what does the network learn when the error is propagated back in each iteration? Well, as previously noted, **the weights keep updating based on the error of the network in training.** First, the embedding matrix will be updated in each iteration. Second, there are a bunch of weight matrices related to the gates in the LSTM units, which will be changed. Finally, the weights related to the Softmax layer, which somehow plays the decoding role for the encoded words in the embedding layer.\n",
    "\n",
    "<img src=\"https://jupyterlab-0-labs-prod-jupyterlab-us-east-0.labs.cognitiveclass.ai/user/mathildeduvi/files/labs/LSTM03.png?_xsrf=MnwxOjB8MTA6MTcxNzQzNTEwOHw1Ol94c3JmfDEzMjpZbVJsTkdJM01HWTRORGsxTkRabE9EbGtOVGxpT0RZM04ySm1aVGMzTURnNk4ySmtNV1V4TW1Ga09XTXlabVF4WkRjeVl6azJNalprWlRNd1kyVTFZVEExWWpFNVpHRTBOelpsTVRaaU1qRTVObVprTVRVMlltTmtNalJrWlRaa1pnPT18ZjI0MWI2YTA1MWI3Y2RhNzg3ZjBmMjcwZjUxYTBjYWUxN2EwMWJjODU0NDc0Yjk1ZDU2ZWRiMjg4ODZiYmE0Ng\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to import the necessary modules for our code. We need <b><code>numpy</code></b> and <b><code>tensorflow</code></b>, obviously. Additionally, we can import directly the <b><code>tensorflow.models.rnn</code></b> model, which includes the function for building RNNs, and <b><code>tensorflow.models.rnn.ptb.reader</code></b> which is the helper module for getting the input data from the dataset we just downloaded.\n",
    "\n",
    "If you want to learn more take a look at https://github.com/tensorflow/models/blob/master/tutorials/rnn/ptb/reader.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.9.0\n",
    "#!pip install numpy==1.21.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 07:32:14.457703: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-24 07:32:14.463802: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-24 07:32:14.463861: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "if not tf.__version__ == '2.9.0':\n",
    "    print(tf.__version__)\n",
    "    raise ValueError('please upgrade to TensorFlow 2.9.0, or restart your Kernel (Kernel->Restart & Clear Output)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT! => Please restart the kernel by clicking on \"Kernel\"->\"Restart and Clear Outout\" and wait until all output disapears. Then your changes are beeing picked up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir data\n",
    "#!mkdir data/ptb\n",
    "#!wget -q -O data/ptb/reader.py https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0120EN-SkillsNetwork/labs/Week3/data/ptb/reader.py\n",
    "#!cp data/ptb/reader.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "\"\"\"Utilities for parsing PTB text files.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def _read_words(filename):\n",
    "  with tf.io.gfile.GFile(filename, \"r\") as f:\n",
    "    return f.read().replace(\"\\n\", \"<eos>\").split()\n",
    "\n",
    "\n",
    "def _build_vocab(filename):\n",
    "  data = _read_words(filename)\n",
    "\n",
    "  counter = collections.Counter(data)\n",
    "  count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
    "\n",
    "  words, _ = list(zip(*count_pairs))\n",
    "  word_to_id = dict(zip(words, range(len(words))))\n",
    "\n",
    "  return word_to_id\n",
    "\n",
    "\n",
    "def _file_to_word_ids(filename, word_to_id):\n",
    "  data = _read_words(filename)\n",
    "  return [word_to_id[word] for word in data if word in word_to_id]\n",
    "\n",
    "\n",
    "def ptb_raw_data(data_path=None):\n",
    "  \"\"\"Load PTB raw data from data directory \"data_path\".\n",
    "\n",
    "  Reads PTB text files, converts strings to integer ids,\n",
    "  and performs mini-batching of the inputs.\n",
    "\n",
    "  The PTB dataset comes from Tomas Mikolov's webpage:\n",
    "\n",
    "  http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
    "\n",
    "  Args:\n",
    "    data_path: string path to the directory where simple-examples.tgz has\n",
    "      been extracted.\n",
    "\n",
    "  Returns:\n",
    "    tuple (train_data, valid_data, test_data, vocabulary)\n",
    "    where each of the data objects can be passed to PTBIterator.\n",
    "  \"\"\"\n",
    "\n",
    "  train_path = os.path.join(data_path, \"ptb.train.txt\")\n",
    "  valid_path = os.path.join(data_path, \"ptb.valid.txt\")\n",
    "  test_path = os.path.join(data_path, \"ptb.test.txt\")\n",
    "\n",
    "  word_to_id = _build_vocab(train_path)\n",
    "  train_data = _file_to_word_ids(train_path, word_to_id)\n",
    "  valid_data = _file_to_word_ids(valid_path, word_to_id)\n",
    "  test_data = _file_to_word_ids(test_path, word_to_id)\n",
    "  vocabulary = len(word_to_id)\n",
    "  return train_data, valid_data, test_data, vocabulary, word_to_id\n",
    "\n",
    "\n",
    "def ptb_iterator(raw_data, batch_size, num_steps):\n",
    "  \"\"\"Iterate on the raw PTB data.\n",
    "\n",
    "  This generates batch_size pointers into the raw PTB data, and allows\n",
    "  minibatch iteration along these pointers.\n",
    "\n",
    "  Args:\n",
    "    raw_data: one of the raw data outputs from ptb_raw_data.\n",
    "    batch_size: int, the batch size.\n",
    "    num_steps: int, the number of unrolls.\n",
    "\n",
    "  Yields:\n",
    "    Pairs of the batched data, each a matrix of shape [batch_size, num_steps].\n",
    "    The second element of the tuple is the same data time-shifted to the\n",
    "    right by one.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: if batch_size or num_steps are too high.\n",
    "  \"\"\"\n",
    "  raw_data = np.array(raw_data, dtype=np.int32)\n",
    "\n",
    "  data_len = len(raw_data)\n",
    "  batch_len = data_len // batch_size\n",
    "  data = np.zeros([batch_size, batch_len], dtype=np.int32)\n",
    "  for i in range(batch_size):\n",
    "    data[i] = raw_data[batch_len * i:batch_len * (i + 1)]\n",
    "\n",
    "  epoch_size = (batch_len - 1) // num_steps\n",
    "\n",
    "  if epoch_size == 0:\n",
    "    raise ValueError(\"epoch_size == 0, decrease batch_size or num_steps\")\n",
    "\n",
    "  for i in range(epoch_size):\n",
    "    x = data[:, i*num_steps:(i+1)*num_steps]\n",
    "    y = data[:, i*num_steps+1:(i+1)*num_steps+1]\n",
    "    yield (x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"building_lstm_model\"></a>\n",
    "<h2>Building the LSTM model for Language Modeling</h2>\n",
    "Now that we know exactly what we are doing, we can start building our model using TensorFlow. The very first thing we need to do is download and extract the <code>simple-examples</code> dataset, which can be done by executing the code cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-24 07:32:17--  http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
      "Resolving www.fit.vutbr.cz (www.fit.vutbr.cz)... 147.229.9.23, 147.229.9.23\n",
      "Connecting to www.fit.vutbr.cz (www.fit.vutbr.cz)|147.229.9.23|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 34869662 (33M) [application/x-gtar]\n",
      "Saving to: ‘simple-examples.tgz.6’\n",
      "\n",
      "simple-examples.tgz 100%[===================>]  33.25M  9.32MB/s    in 4.7s    \n",
      "\n",
      "2024-05-24 07:32:23 (7.11 MB/s) - ‘simple-examples.tgz.6’ saved [34869662/34869662]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz \n",
    "!tar xzf simple-examples.tgz -C data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, for the sake of making it easy to play around with the model's hyperparameters, we can declare them beforehand. Feel free to change these -- you will see a difference in performance each time you change those!  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial weight scale\n",
    "init_scale = 0.1\n",
    "#Initial learning rate\n",
    "learning_rate = 1.0\n",
    "#Maximum permissible norm for the gradient (For gradient clipping -- another measure against Exploding Gradients)\n",
    "max_grad_norm = 5\n",
    "#The number of layers in our model\n",
    "num_layers = 2\n",
    "#The total number of recurrence steps, also known as the number of layers when our RNN is \"unfolded\"\n",
    "num_steps = 20\n",
    "#The number of processing units (neurons) in the hidden layers\n",
    "hidden_size_l1 = 256\n",
    "hidden_size_l2 = 128\n",
    "#The maximum number of epochs trained with the initial learning rate\n",
    "max_epoch_decay_lr = 4\n",
    "#The total number of epochs in training\n",
    "max_epoch = 15\n",
    "#The probability for keeping data in the Dropout Layer (This is an optimization, but is outside our scope for this notebook!)\n",
    "#At 1, we ignore the Dropout Layer wrapping.\n",
    "keep_prob = 1\n",
    "#The decay for the learning rate\n",
    "decay = 0.5\n",
    "#The size for each batch of data\n",
    "batch_size = 30\n",
    "#The size of our vocabulary\n",
    "vocab_size = 10000\n",
    "embeding_vector_size= 200\n",
    "#Training flag to separate training from testing\n",
    "is_training = 1\n",
    "#Data directory for our dataset\n",
    "data_dir = \"data/simple-examples/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some clarifications for LSTM architecture based on the arguments:\n",
    "\n",
    "Network structure:\n",
    "<ul>\n",
    "    <li>In this network, the number of LSTM cells are 2. To give the model more expressive power, we can add multiple layers of LSTMs to process the data. The output of the first layer will become the input of the second and so on.\n",
    "    </li>\n",
    "    <li>The recurrence steps is 20, that is, when our RNN is \"Unfolded\", the recurrence step is 20.</li>   \n",
    "    <li>the structure is like:\n",
    "        <ul>\n",
    "            <li>200 input units -> [200x200] Weight -> 200 Hidden units (first layer) -> [200x200] Weight matrix  -> 200 Hidden units (second layer) ->  [200] weight Matrix -> 200 unit output</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "<br>\n",
    "\n",
    "Input layer: \n",
    "<ul>\n",
    "    <li>The network has 200 input units.</li>\n",
    "    <li>Suppose each word is represented by an embedding vector of dimensionality e=200. The input layer of each cell will have 200 linear units. These e=200 linear units are connected to each of the h=200 LSTM units in the hidden layer (assuming there is only one hidden layer, though our case has 2 layers).\n",
    "    </li>\n",
    "    <li>The input shape is [batch_size, num_steps], that is [30x20]. It will turn into [30x20x200] after embedding, and then 20x[30x200]\n",
    "    </li>\n",
    "</ul>\n",
    "<br>\n",
    "\n",
    "Hidden layer:\n",
    "<ul>\n",
    "    <li>Each LSTM has 200 hidden units which is equivalent to the dimensionality of the embedding words and output.</li>\n",
    "</ul>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is adapted from the <a href=\"https://github.com/tensorflow/models\">PTBModel</a> example bundled with the TensorFlow source code.\n",
    "\n",
    "\n",
    "<h3>Training data</h3>\n",
    "The story starts from data:\n",
    "<ul>\n",
    "    <li>Train data is a list of words, of size 929589, represented by numbers, e.g. [9971, 9972, 9974, 9975,...]</li>\n",
    "    <li>We read data as mini-batch of size b=30. Assume the size of each sentence is 20 words (num_steps = 20). Then it will take $$floor(\\frac{N}{b \\times h})+1=1548$$ iterations for the learner to go through all sentences once. Where N is the size of the list of words, b is batch size, and h is size of each sentence. So, the number of iterators is 1548\n",
    "    </li>\n",
    "    <li>Each batch data is read from train dataset of size 600, and shape of [30x20]</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the data and separates it into training data, validation data and testing data\n",
    "raw_data = ptb_raw_data(data_dir)\n",
    "train_data, valid_data, test_data, vocab, word_to_id = raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "929589"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aer', 'banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro-quebec', 'ipo', 'kia', 'memotec', 'mlx', 'nahb', 'punts', 'rake', 'regatta', 'rubens', 'sim', 'snack-food', 'ssangyong', 'swapo', 'wachter', '<eos>', 'pierre', '<unk>', 'N', 'years', 'old', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'nov.', 'N', '<eos>', 'mr.', '<unk>', 'is', 'chairman', 'of', '<unk>', 'n.v.', 'the', 'dutch', 'publishing', 'group', '<eos>', 'rudolph', '<unk>', 'N', 'years', 'old', 'and', 'former', 'chairman', 'of', 'consolidated', 'gold', 'fields', 'plc', 'was', 'named', 'a', 'nonexecutive', 'director', 'of', 'this', 'british', 'industrial', 'conglomerate', '<eos>', 'a', 'form', 'of', 'asbestos', 'once', 'used', 'to', 'make', 'kent', 'cigarette', 'filters', 'has', 'caused', 'a', 'high', 'percentage', 'of', 'cancer', 'deaths', 'among', 'a', 'group', 'of']\n"
     ]
    }
   ],
   "source": [
    "def id_to_word(id_list):\n",
    "    line = []\n",
    "    for w in id_list:\n",
    "        for word, wid in word_to_id.items():\n",
    "            if wid == w:\n",
    "                line.append(word)\n",
    "    return line            \n",
    "                \n",
    "\n",
    "print(id_to_word(train_data[0:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets just read one mini-batch now and feed our network:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "itera = ptb_iterator(train_data, batch_size, num_steps)\n",
    "first_touple = itera.__next__()\n",
    "_input_data = first_touple[0]\n",
    "_targets = first_touple[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 20)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at 3 sentences of our input x:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9970, 9971, 9972, 9974, 9975, 9976, 9980, 9981, 9982, 9983, 9984,\n",
       "        9986, 9987, 9988, 9989, 9991, 9992, 9993, 9994, 9995],\n",
       "       [2654,    6,  334, 2886,    4,    1,  233,  711,  834,   11,  130,\n",
       "         123,    7,  514,    2,   63,   10,  514,    8,  605],\n",
       "       [   0, 1071,    4,    0,  185,   24,  368,   20,   31, 3109,  954,\n",
       "          12,    3,   21,    2, 2915,    2,   12,    3,   21]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input_data[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aer', 'banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro-quebec', 'ipo', 'kia', 'memotec', 'mlx', 'nahb', 'punts', 'rake', 'regatta', 'rubens', 'sim']\n"
     ]
    }
   ],
   "source": [
    "print(id_to_word(_input_data[0,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Embeddings</h3>\n",
    "We have to convert the words in our dataset to vectors of numbers. The traditional approach is to use one-hot encoding method that is usually used for converting categorical values to numerical values. However, One-hot encoded vectors are high-dimensional, sparse and in a big dataset, computationally inefficient. So, we use word2vec approach. It is, in fact, a layer in our LSTM network, where the word IDs will be represented as a dense representation before feeding to the LSTM. \n",
    "\n",
    "The embedded vectors also get updated during the training process of the deep neural network.\n",
    "We create the embeddings for our input data. <b>embedding_vocab</b> is matrix of [10000x200] for all 10000 unique words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>embedding_lookup()</b> finds the embedded values for our batch of 30x20 words. It  goes to each row of <code>input_data</code>, and for each word in the row/sentence, finds the correspond vector in <code>embedding_dic<code>. <br>\n",
    "It creates a [30x20x200] tensor, so, the first element of <b>inputs</b> (the first sentence), is a matrix of 20x200, which each row of it, is vector representing a word in the sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(vocab_size, embeding_vector_size,batch_input_shape=(batch_size, num_steps),trainable=True,name=\"embedding_vocab\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 07:32:41.571833: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-05-24 07:32:41.571912: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-05-24 07:32:41.571951: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyterlab-mathildeduvi): /proc/driver/nvidia/version does not exist\n",
      "2024-05-24 07:32:41.572752: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30, 20, 200), dtype=float32, numpy=\n",
       "array([[[-1.49707906e-02,  5.38178533e-03, -6.67852163e-03, ...,\n",
       "         -1.94302686e-02, -4.16717306e-02,  1.97207928e-03],\n",
       "        [ 3.74056138e-02, -4.47807796e-02, -4.70420606e-02, ...,\n",
       "          4.46729325e-02, -2.23738793e-02, -1.07665882e-02],\n",
       "        [-7.31766224e-03, -6.49178028e-03, -4.68126647e-02, ...,\n",
       "         -3.57979536e-03, -1.68513507e-04, -3.58303562e-02],\n",
       "        ...,\n",
       "        [ 3.54414061e-03, -1.76353082e-02,  3.02744992e-02, ...,\n",
       "          1.40910633e-02, -1.98392514e-02,  1.59478821e-02],\n",
       "        [-4.71248887e-02,  4.18930762e-02, -2.38223318e-02, ...,\n",
       "          2.59345211e-02,  4.28702496e-02,  1.80087946e-02],\n",
       "        [-2.23864913e-02,  4.47431840e-02,  2.23970674e-02, ...,\n",
       "         -2.74322759e-02,  4.79324944e-02, -4.44403067e-02]],\n",
       "\n",
       "       [[-1.94406267e-02, -7.72102922e-03,  2.29607895e-03, ...,\n",
       "         -4.99670878e-02,  2.87812240e-02,  3.52482907e-02],\n",
       "        [-5.41709736e-03,  4.19215076e-02,  1.43646039e-02, ...,\n",
       "          1.28492229e-02,  4.59846109e-03, -1.69337615e-02],\n",
       "        [-2.63085961e-02,  4.79891188e-02, -1.42441764e-02, ...,\n",
       "         -9.14417580e-03, -8.05381685e-03, -4.23973799e-03],\n",
       "        ...,\n",
       "        [ 1.40481070e-03,  4.26317789e-02,  5.72103262e-03, ...,\n",
       "          3.17629911e-02,  2.31136717e-02, -1.67693011e-02],\n",
       "        [-4.55126539e-02, -2.50448715e-02,  1.48924440e-03, ...,\n",
       "          1.37067102e-02,  1.98747776e-02,  1.81808323e-03],\n",
       "        [ 3.85424607e-02, -4.07798998e-02, -4.30864803e-02, ...,\n",
       "          8.80612060e-03,  1.04286782e-02, -1.17717870e-02]],\n",
       "\n",
       "       [[ 3.47729810e-02,  3.91505249e-02, -2.78719198e-02, ...,\n",
       "          8.15490633e-03,  3.40547226e-02, -4.20811661e-02],\n",
       "        [-1.87893752e-02,  3.83835770e-02,  1.97889321e-02, ...,\n",
       "          2.16706432e-02, -2.40187291e-02, -2.99432874e-02],\n",
       "        [-1.52112357e-02,  4.41470630e-02,  1.12099275e-02, ...,\n",
       "         -4.92786057e-02,  2.79679559e-02, -1.95098277e-02],\n",
       "        ...,\n",
       "        [-1.31770745e-02, -1.69280544e-02, -4.09148224e-02, ...,\n",
       "          7.01626390e-03,  2.81447507e-02,  4.89362516e-02],\n",
       "        [-3.17791328e-02, -3.81941088e-02, -4.41393964e-02, ...,\n",
       "         -4.34664153e-02,  1.97764151e-02,  1.94488838e-03],\n",
       "        [ 1.43366121e-02, -3.69940512e-02, -4.73038442e-02, ...,\n",
       "          2.36697905e-02, -3.70506868e-02,  3.86134498e-02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.17578618e-02,  3.28937434e-02, -3.78841534e-02, ...,\n",
       "          2.37977766e-02,  1.27665699e-05, -2.32054722e-02],\n",
       "        [-3.75229605e-02, -2.30505951e-02, -8.93796608e-03, ...,\n",
       "          9.53710079e-03, -2.98103336e-02,  4.27526236e-03],\n",
       "        [ 1.13088489e-02,  3.62025388e-02,  1.27740242e-02, ...,\n",
       "         -1.07193366e-02,  1.31355599e-03, -1.27459392e-02],\n",
       "        ...,\n",
       "        [-7.99845532e-03, -2.50540972e-02, -8.85059685e-03, ...,\n",
       "         -3.86254787e-02, -7.12863356e-03, -1.40793808e-02],\n",
       "        [ 4.79314663e-02, -1.88616998e-02,  4.97514345e-02, ...,\n",
       "         -1.54415853e-02, -5.62895089e-04,  3.26793529e-02],\n",
       "        [-2.59376299e-02,  5.24667650e-03, -2.60067228e-02, ...,\n",
       "          3.33501026e-03,  6.50309399e-03,  1.91190094e-03]],\n",
       "\n",
       "       [[ 1.51180960e-02, -3.45975049e-02,  4.08184528e-03, ...,\n",
       "         -2.61415839e-02, -2.14768574e-03,  8.28184187e-04],\n",
       "        [ 9.12559032e-03,  3.93168665e-02, -1.41061433e-02, ...,\n",
       "          2.26836093e-02,  1.81627162e-02, -2.76654009e-02],\n",
       "        [-1.52112357e-02,  4.41470630e-02,  1.12099275e-02, ...,\n",
       "         -4.92786057e-02,  2.79679559e-02, -1.95098277e-02],\n",
       "        ...,\n",
       "        [-1.10743195e-03, -4.66810465e-02,  2.02387609e-02, ...,\n",
       "          1.02098696e-02,  1.60849802e-02,  4.40619886e-04],\n",
       "        [-5.41709736e-03,  4.19215076e-02,  1.43646039e-02, ...,\n",
       "          1.28492229e-02,  4.59846109e-03, -1.69337615e-02],\n",
       "        [ 1.25931241e-02, -3.79204378e-02, -1.82765014e-02, ...,\n",
       "         -1.67598613e-02,  8.78137350e-03,  4.06134129e-03]],\n",
       "\n",
       "       [[-1.84386000e-02,  4.02025469e-02, -3.28449756e-02, ...,\n",
       "         -2.29901914e-02, -2.30352879e-02,  1.07174031e-02],\n",
       "        [ 2.94735767e-02, -2.77251136e-02, -2.14905869e-02, ...,\n",
       "          2.02355646e-02, -3.25625762e-02, -1.35878548e-02],\n",
       "        [-3.77659425e-02, -5.37636131e-03,  3.25166620e-02, ...,\n",
       "          3.39588858e-02,  2.14872472e-02, -3.44765075e-02],\n",
       "        ...,\n",
       "        [-4.52448614e-02, -1.31906196e-03,  2.48537101e-02, ...,\n",
       "         -4.84122746e-02, -4.01414260e-02, -3.37366946e-02],\n",
       "        [ 4.96774353e-02,  8.91024992e-03,  3.77380289e-02, ...,\n",
       "          2.93334983e-02, -2.78115273e-03, -1.98230632e-02],\n",
       "        [ 4.63300608e-02,  4.98607494e-02, -2.42636353e-03, ...,\n",
       "          4.32534851e-02,  4.54628803e-02,  3.26480605e-02]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define where to get the data for our embeddings from\n",
    "inputs = embedding_layer(_input_data)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Constructing Recurrent Neural Networks</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we create the stacked LSTM using <b>tf.keras.layers.StackedRNNCells</b>, which is a 2 layer LSTM network:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_cell_l1 = tf.keras.layers.LSTMCell(hidden_size_l1)\n",
    "lstm_cell_l2 = tf.keras.layers.LSTMCell(hidden_size_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_lstm = tf.keras.layers.StackedRNNCells([lstm_cell_l1, lstm_cell_l2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>**tf.keras.layers.RNN</b> creates a recurrent neural network using <b>stacked_lstm**</b>. \n",
    "\n",
    "The input should be a Tensor of shape: [batch_size, max_time, embedding_vector_size], in our case it would be (30, 20, 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer  =  tf.keras.layers.RNN(stacked_lstm,[batch_size, num_steps],return_state=False,stateful=True,trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we initialize the states of the nework:\n",
    "\n",
    "<h4>_initial_state</h4>\n",
    "\n",
    "For each LSTM, there are 2 state matrices, c\\_state and m\\_state.  c_state and m_state represent \"Memory State\" and \"Cell State\". Each hidden layer, has a vector of size 30, which keeps the states. so, for 200 hidden units in each LSTM, we have a matrix of size [30x200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state = tf.Variable(tf.zeros([batch_size,embeding_vector_size]),trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.inital_state = init_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(30, 200) dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.inital_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so, lets look at the outputs. The output of the stackedLSTM comes from 128 hidden_layer, and in each time step(=20), one of them get activated. we use the linear activation to map the 128 hidden layer to a [30X20 matrix]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = layer(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30, 20, 128), dtype=float32, numpy=\n",
       "array([[[ 3.98972013e-04, -3.24883615e-04,  1.39436277e-04, ...,\n",
       "          4.37740935e-04,  5.47910924e-04,  1.67856261e-03],\n",
       "        [ 9.08698654e-04, -1.81250600e-03,  4.16038412e-04, ...,\n",
       "         -9.90007189e-04,  1.19946571e-03,  3.04066390e-03],\n",
       "        [ 2.93977489e-03, -3.13962880e-03,  2.18234777e-06, ...,\n",
       "         -1.38931896e-03,  1.64805131e-03,  4.96839732e-03],\n",
       "        ...,\n",
       "        [ 4.46141558e-03, -3.33527545e-03, -5.91992075e-03, ...,\n",
       "          7.56060763e-04,  7.05041690e-03,  7.65108876e-03],\n",
       "        [ 5.25824260e-03, -2.21831957e-03, -6.24949671e-03, ...,\n",
       "          1.11821946e-03,  7.49122538e-03,  7.19130784e-03],\n",
       "        [ 5.66798775e-03, -6.27889938e-04, -5.42882038e-03, ...,\n",
       "          1.23760127e-03,  7.14507280e-03,  6.71417266e-03]],\n",
       "\n",
       "       [[ 3.13355966e-04, -4.84293501e-04,  1.05029054e-03, ...,\n",
       "          8.35961895e-04,  8.17746797e-04, -6.94340502e-04],\n",
       "        [ 7.75108056e-04, -1.70487154e-03,  1.46446051e-03, ...,\n",
       "          1.37980783e-03,  1.21882546e-03, -1.50223344e-03],\n",
       "        [ 5.30396181e-04, -4.07019490e-03,  1.50091725e-03, ...,\n",
       "          2.17387639e-03,  1.10607117e-03, -1.55541813e-03],\n",
       "        ...,\n",
       "        [-6.86566671e-03, -8.06794036e-04, -5.43563953e-03, ...,\n",
       "          2.47597229e-03, -1.34745659e-03,  2.36652140e-03],\n",
       "        [-5.55232214e-03,  8.61335837e-04, -5.89296222e-03, ...,\n",
       "          2.87967036e-03, -2.38621864e-03, -4.21714300e-04],\n",
       "        [-4.80247615e-03,  1.58978812e-03, -6.14524540e-03, ...,\n",
       "          4.28126566e-03, -2.83696828e-03, -1.94495311e-03]],\n",
       "\n",
       "       [[ 8.95385398e-04,  2.25144904e-03,  8.45373666e-04, ...,\n",
       "          3.02510976e-04, -6.92469301e-04,  1.04140854e-04],\n",
       "        [ 2.01217388e-03,  4.21337597e-03,  1.82257884e-03, ...,\n",
       "         -9.92910136e-05, -4.28920175e-04, -4.27076797e-04],\n",
       "        [ 2.25432869e-03,  5.63437119e-03,  2.12274119e-03, ...,\n",
       "          7.78472924e-04, -1.21649995e-03, -2.75424740e-04],\n",
       "        ...,\n",
       "        [ 4.85796481e-03,  1.98548357e-03,  5.46429539e-03, ...,\n",
       "         -3.57921794e-03, -7.45867006e-03,  1.67952443e-04],\n",
       "        [ 3.21951718e-03,  1.72709266e-03,  6.68035401e-03, ...,\n",
       "         -4.01150854e-03, -7.55551178e-03, -3.94434464e-04],\n",
       "        [ 3.34208203e-03,  1.17883482e-03,  7.16069015e-03, ...,\n",
       "         -3.95740988e-03, -7.01510860e-03, -1.14207249e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.49767485e-03, -7.92454957e-05,  1.09703024e-03, ...,\n",
       "         -2.17816760e-05,  1.97951551e-04,  2.22653546e-03],\n",
       "        [-1.56730367e-03,  2.56894127e-04,  1.18259620e-03, ...,\n",
       "         -2.57007661e-04, -3.94482980e-04,  2.95362365e-03],\n",
       "        [-9.21779836e-04,  2.54934828e-04,  1.04194868e-03, ...,\n",
       "         -4.49244224e-04, -8.04345240e-04,  3.63089121e-03],\n",
       "        ...,\n",
       "        [ 4.68926650e-04, -2.57384870e-03,  3.62704415e-03, ...,\n",
       "         -5.94531652e-03,  4.29941683e-05, -2.24856450e-03],\n",
       "        [ 1.59991346e-03, -3.41105927e-03,  2.81417673e-03, ...,\n",
       "         -6.07292494e-03, -1.29701057e-03, -2.02805293e-03],\n",
       "        [ 5.90633717e-04, -4.22804570e-03,  1.21358060e-03, ...,\n",
       "         -5.64801740e-03, -2.29729619e-03, -2.28949566e-03]],\n",
       "\n",
       "       [[ 3.63795087e-04, -7.49225146e-04, -1.88526901e-04, ...,\n",
       "         -1.06651615e-03, -4.02325357e-04, -1.49598019e-03],\n",
       "        [ 3.79933947e-04, -4.03365993e-04, -4.43733115e-05, ...,\n",
       "         -1.24800892e-03, -1.33663020e-03, -1.22209650e-03],\n",
       "        [-2.47213058e-04,  5.41751506e-04, -2.69099226e-04, ...,\n",
       "         -1.41338111e-04, -3.06026940e-03, -6.31033618e-04],\n",
       "        ...,\n",
       "        [ 8.17594642e-04,  1.39272725e-03, -4.78400104e-03, ...,\n",
       "         -8.70373286e-03, -2.82849814e-03, -5.72571438e-03],\n",
       "        [ 9.91621753e-04, -5.72901299e-05, -5.08479727e-03, ...,\n",
       "         -8.37755948e-03, -2.37823604e-03, -6.39665499e-03],\n",
       "        [ 2.07874994e-03,  1.05563937e-04, -4.06786054e-03, ...,\n",
       "         -7.69070582e-03,  1.63075994e-04, -6.38312241e-03]],\n",
       "\n",
       "       [[-5.84505207e-04,  1.72127306e-03, -1.31514855e-04, ...,\n",
       "          6.29494782e-04, -1.19741529e-03, -5.87384391e-04],\n",
       "        [-8.20569287e-04,  1.50632800e-03,  3.14079633e-04, ...,\n",
       "          1.06974004e-03, -3.10015073e-03, -5.33653831e-04],\n",
       "        [-1.95416436e-03,  1.19798793e-03, -9.19664104e-04, ...,\n",
       "          1.79049920e-03, -4.25225310e-03,  3.39130405e-04],\n",
       "        ...,\n",
       "        [ 3.23867938e-03, -4.72318061e-04,  9.87474574e-04, ...,\n",
       "         -1.72137888e-03,  5.28982375e-04,  5.67984348e-03],\n",
       "        [ 1.59756292e-03,  2.57592299e-03,  2.06159195e-04, ...,\n",
       "         -2.04346864e-03, -4.87897720e-04,  5.52753918e-03],\n",
       "        [-1.54989399e-03,  3.98029666e-03, -1.31121068e-03, ...,\n",
       "         -2.09236494e-03, -2.70960503e-04,  6.55372394e-03]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dense layer</h2>\n",
    "We now create densely-connected neural network layer that would reshape the outputs tensor from  [30 x 20 x 128] to [30 x 20 x 10000].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.layers.Dense(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_outputs  = dense(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the output from dense layer:  (30, 20, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of the output from dense layer: \", logits_outputs.shape) #(batch_size, sequence_length, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Activation layer</h2>\n",
    "\n",
    "\n",
    "A softmax activation layers is also then applied to derive the probability of the output being in any of the multiclass(10000 in this case) possibilities. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = tf.keras.layers.Activation('softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_words_prob = activation(logits_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([30, 20, 10000])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the output from the activation layer:  (30, 20, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of the output from the activation layer: \", output_words_prob.shape) #(batch_size, sequence_length, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the probability of observing words for t=0 to t=20 (first batch):\n",
    " for each word, 1000 probabilities (one per word in the dictionnary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of observing words in t=0 to t=20 tf.Tensor(\n",
      "[[1.00004778e-04 9.99826952e-05 9.99933400e-05 ... 1.00002988e-04\n",
      "  1.00009784e-04 1.00005695e-04]\n",
      " [1.00005578e-04 9.99789045e-05 1.00004348e-04 ... 1.00008168e-04\n",
      "  9.99949261e-05 9.99819022e-05]\n",
      " [1.00009609e-04 9.99862605e-05 1.00005280e-04 ... 1.00028788e-04\n",
      "  9.99894473e-05 9.99625699e-05]\n",
      " ...\n",
      " [9.99426920e-05 1.00037469e-04 1.00008379e-04 ... 9.99593467e-05\n",
      "  9.99650947e-05 1.00037643e-04]\n",
      " [9.99439435e-05 1.00022815e-04 1.00009849e-04 ... 9.99361437e-05\n",
      "  9.99467811e-05 1.00047742e-04]\n",
      " [9.99297336e-05 1.00010388e-04 1.00004298e-04 ... 9.99351978e-05\n",
      "  9.99327967e-05 1.00054349e-04]], shape=(20, 10000), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"The probability of observing words in t=0 to t=20\", output_words_prob[0,0:num_steps])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prediction</h3>\n",
    "What is the word that corresponds to the probability output? Lets use the maximum probability:\n",
    "\n",
    "Most likely across the 1000 words of the dictionnary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4442, 6173, 1360, 1360, 5445, 5445, 1263, 1360, 1360, 1800, 8212,\n",
       "       8212,  146,  146, 2544, 4660, 4660, 4660, 6934, 6934])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_pred = np.argmax(output_words_prob[0,0:num_steps], axis=1)\n",
    "words_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['column', 'prof.', 'passed', 'passed', 'lobbyist', 'lobbyist', 'cable', 'passed', 'passed', 'ready', 'lubricants', 'lubricants', 'board', 'board', 'introduce', 'crops', 'crops', 'crops', 'hailed', 'hailed']\n"
     ]
    }
   ],
   "source": [
    "print(id_to_word(words_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what is the ground truth for the first word of first sentence? You can get it from target tensor, if you want to find the embedding vector: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9971, 9972, 9974, 9975, 9976, 9980, 9981, 9982, 9983, 9984, 9986,\n",
       "       9987, 9988, 9989, 9991, 9992, 9993, 9994, 9995, 9996], dtype=int32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro-quebec', 'ipo', 'kia', 'memotec', 'mlx', 'nahb', 'punts', 'rake', 'regatta', 'rubens', 'sim', 'snack-food']\n"
     ]
    }
   ],
   "source": [
    "print(id_to_word(_targets[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Objective function</h4>\n",
    "\n",
    "\n",
    "How similar the predicted words are to the target words?\n",
    "\n",
    "\n",
    "Now we have to define our objective function, to calculate the similarity of predicted values to ground truth, and then, penalize the model with the error. Our objective is to minimize loss function, that is, to minimize the average negative log probability of the target words:\n",
    "\n",
    "$$\\text{loss} = -\\frac{1}{N}\\sum_{i=1}^{N} \\ln p_{\\text{target}_i}$$\n",
    "\n",
    "This function is already implemented and available in TensorFlow through *tf.keras.losses.sparse_categorical_crossentropy*. It calculates the categorical cross-entropy loss for <b>logits</b> and the <b>target</b> sequence.  \n",
    "\n",
    "The arguments of this function are:  \n",
    "<ul>\n",
    "    <li>logits: List of 2D Tensors of shape [batch_size x num_decoder_symbols].</li>  \n",
    "    <li>targets: List of 1D batch-sized int32 Tensors of the same length as logits.</li>   \n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossentropy(y_true, y_pred):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss  = crossentropy(_targets, output_words_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the first 10 values of loss:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([9.210443 , 9.210389 , 9.210133 , 9.210294 , 9.210607 , 9.210931 ,\n",
       "       9.210765 , 9.2094555, 9.210026 , 9.210965 ], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss[0,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define cost as average of the losses:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=184.20703>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = tf.reduce_sum(loss / batch_size)\n",
    "cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training</h3>\n",
    "\n",
    "To do training for our network, we have to take the following steps:\n",
    "<ol>\n",
    "    <li>Define the optimizer.</li>\n",
    "    <li>Assemble layers to build model.</li>\n",
    "    <li>Calculate the gradients based on the loss function.</li>\n",
    "    <li>Apply the optimizer to the variables/gradients tuple.</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>1. Define Optimizer</h4>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable for the learning rate\n",
    "lr = tf.Variable(0.0, trainable=False)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr, clipnorm=max_grad_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2. Assemble layers to build model.</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_vocab (Embedding)  (30, 20, 200)            2000000   \n",
      "                                                                 \n",
      " rnn (RNN)                   (30, 20, 128)             671088    \n",
      "                                                                 \n",
      " dense (Dense)               (30, 20, 10000)           1290000   \n",
      "                                                                 \n",
      " activation (Activation)     (30, 20, 10000)           0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,961,088\n",
      "Trainable params: 3,955,088\n",
      "Non-trainable params: 6,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(layer)\n",
    "model.add(dense)\n",
    "model.add(activation)\n",
    "model.compile(loss=crossentropy, optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4>2. Trainable Variables</h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a variable, if you passed <i>trainable=True</i>, the variable constructor automatically adds new variables to the graph collection <b>GraphKeys.TRAINABLE_VARIABLES</b>. Now, using <i>tf.trainable_variables()</i> you can get all variables created with <b>trainable=True</b>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all TensorFlow variables marked as \"trainable\" (i.e. all of them except _lr, which we just created)\n",
    "tvars = model.trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we can find the name and scope of all variables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['embedding_vocab/embeddings:0',\n",
       " 'rnn/stacked_rnn_cells/lstm_cell/kernel:0',\n",
       " 'rnn/stacked_rnn_cells/lstm_cell/recurrent_kernel:0',\n",
       " 'rnn/stacked_rnn_cells/lstm_cell/bias:0',\n",
       " 'rnn/stacked_rnn_cells/lstm_cell_1/kernel:0',\n",
       " 'rnn/stacked_rnn_cells/lstm_cell_1/recurrent_kernel:0',\n",
       " 'rnn/stacked_rnn_cells/lstm_cell_1/bias:0',\n",
       " 'dense/kernel:0',\n",
       " 'dense/bias:0']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tvars] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3. Calculate the gradients based on the loss function</h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient**: The gradient of a function is the slope of its derivative (line), or in other words, the rate of change of a function. It's a vector (a direction to move) that points in the direction of greatest increase of the function, and calculated by the <b>derivative</b> operation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets recall the gradient function using an toy example:\n",
    "$$ z = \\left(2x^2 + 3xy\\right)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(1.0)\n",
    "y =  tf.constant(2.0)\n",
    "with tf.GradientTape(persistent=True) as g:\n",
    "    g.watch(x)\n",
    "    g.watch(y)\n",
    "    func_test = 2 * x * x + 3 * x * y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>tf.gradients()</b> function allows you to compute the symbolic gradient of one tensor with respect to one or more other tensors—including variables. <b>tf.gradients(func, xs)</b> constructs symbolic partial derivatives of sum of <b>func</b> w.r.t. <i>x</i> in <b>xs</b>. \n",
    "\n",
    "Now, lets look at the derivitive w.r.t. <b>var_x</b>:\n",
    "$$ \\frac{\\partial \\:}{\\partial \\:x}\\left(2x^2 + 3xy\\right) = 4x + 3y $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "var_grad = g.gradient(func_test, x) # Will compute to 10.0\n",
    "print(var_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the derivative w.r.t. <b>var_y</b>:\n",
    "$$ \\frac{\\partial \\:}{\\partial \\:y}\\left(2x^2 + 3xy\\right) = 3x $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "var_grad = g.gradient(func_test, y) # Will compute to 3.0\n",
    "print(var_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can look at gradients w.r.t all variables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    # Forward pass.\n",
    "    output_words_prob = model(_input_data)\n",
    "    # Loss value for this batch.\n",
    "    loss  = crossentropy(_targets, output_words_prob)\n",
    "    cost = tf.reduce_sum(loss,axis=0) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gradients of loss wrt the trainable variables.\n",
    "grad_t_list = tape.gradient(cost, tvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7f8d89502f50>, <tf.Tensor: shape=(200, 1024), dtype=float32, numpy=\n",
      "array([[ 2.91566948e-09, -1.06713912e-07, -6.02608566e-07, ...,\n",
      "         1.54288884e-07,  6.73811655e-08, -1.58908307e-07],\n",
      "       [ 2.82572671e-07, -3.25115167e-07,  9.03295785e-08, ...,\n",
      "        -2.08330050e-07,  1.09390115e-07, -6.53377526e-07],\n",
      "       [-6.47504407e-07,  1.00850954e-07,  5.39669259e-07, ...,\n",
      "         3.38197822e-07, -1.27664009e-07, -4.08838844e-07],\n",
      "       ...,\n",
      "       [-1.56591256e-07,  3.97478033e-08,  4.58209286e-07, ...,\n",
      "         1.15946968e-07,  3.30604308e-08, -2.67116349e-07],\n",
      "       [-4.37108952e-07, -5.22484243e-07,  4.42427222e-07, ...,\n",
      "         4.60641701e-07,  3.20872232e-07, -1.14021915e-07],\n",
      "       [-3.16484090e-07,  5.18981892e-07,  2.73768421e-08, ...,\n",
      "        -1.25576065e-07,  1.16187110e-07,  5.03616661e-07]], dtype=float32)>, <tf.Tensor: shape=(256, 1024), dtype=float32, numpy=\n",
      "array([[ 6.86578971e-08, -1.06317756e-07,  1.57273718e-07, ...,\n",
      "         8.96402170e-08, -6.43866755e-08,  5.22124495e-08],\n",
      "       [-1.88319248e-07,  1.37902092e-07,  1.04651349e-07, ...,\n",
      "        -1.41432054e-07,  8.31990477e-08,  2.75974017e-08],\n",
      "       [-1.71781323e-07, -2.22011103e-08, -4.89744849e-08, ...,\n",
      "         1.55570774e-08, -1.48640069e-07,  4.62469139e-08],\n",
      "       ...,\n",
      "       [ 1.00457441e-07,  5.40705933e-08,  1.12140192e-07, ...,\n",
      "         1.12102271e-07, -7.32230490e-08,  2.53691553e-07],\n",
      "       [ 6.57814070e-09,  1.07933516e-07, -2.38810642e-08, ...,\n",
      "         1.62184399e-08, -2.14367226e-08,  1.32388507e-07],\n",
      "       [ 3.54502525e-08, -9.84170754e-08, -1.32598288e-08, ...,\n",
      "        -1.48308743e-07, -1.16296476e-07, -3.23217165e-07]], dtype=float32)>, <tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
      "array([ 1.0477739e-05,  7.6954202e-06,  1.7209029e-05, ...,\n",
      "       -1.5901034e-05, -1.0130257e-06,  1.9723371e-05], dtype=float32)>, <tf.Tensor: shape=(256, 512), dtype=float32, numpy=\n",
      "array([[ 3.46472603e-07, -1.99199803e-08,  5.81054351e-08, ...,\n",
      "        -2.95971461e-08, -3.50905154e-08, -1.09949823e-07],\n",
      "       [-1.55573034e-07,  5.86723203e-08,  2.28113265e-07, ...,\n",
      "        -1.16664090e-07, -1.88337395e-07,  1.55478659e-07],\n",
      "       [-2.24203418e-07,  9.90255700e-08, -2.12693152e-09, ...,\n",
      "         9.21307901e-08,  1.53319874e-07,  2.95831683e-07],\n",
      "       ...,\n",
      "       [ 1.35374975e-07,  3.90487173e-07,  1.04070175e-07, ...,\n",
      "         1.72491681e-07, -4.77408406e-08,  1.55023983e-07],\n",
      "       [-9.79586687e-08,  1.52375108e-07, -1.81927220e-07, ...,\n",
      "        -1.64495887e-07,  2.93793846e-07, -6.99883813e-08],\n",
      "       [-4.60568657e-07, -1.49461115e-07,  1.50361444e-07, ...,\n",
      "         6.92100741e-08, -2.10188631e-08,  1.16189725e-08]], dtype=float32)>, <tf.Tensor: shape=(128, 512), dtype=float32, numpy=\n",
      "array([[ 5.57973351e-07,  8.21946031e-08, -1.07975865e-07, ...,\n",
      "        -1.33970545e-07, -1.01657299e-07,  5.32306004e-08],\n",
      "       [-3.51538922e-08, -2.12892701e-07,  1.56294160e-08, ...,\n",
      "        -2.86850650e-08, -1.22578598e-07, -1.18734427e-07],\n",
      "       [ 2.42569996e-07,  3.49666664e-07, -9.33414697e-08, ...,\n",
      "         8.89265834e-08, -1.99786058e-07, -1.18371034e-07],\n",
      "       ...,\n",
      "       [ 1.35862246e-08, -7.40085255e-08, -1.43901246e-08, ...,\n",
      "         1.57187927e-07, -9.99524161e-08,  3.80135923e-08],\n",
      "       [ 2.40179588e-07,  3.39011535e-07, -9.75441452e-08, ...,\n",
      "         9.87264848e-09, -1.21942080e-07, -6.39013962e-08],\n",
      "       [ 6.41360387e-08,  5.05267401e-08, -6.02255241e-08, ...,\n",
      "         1.60260072e-08, -1.37589609e-07,  2.52284764e-07]], dtype=float32)>, <tf.Tensor: shape=(512,), dtype=float32, numpy=\n",
      "array([ 1.00473726e-05, -1.42586332e-05, -5.65112532e-06, -1.33186350e-05,\n",
      "        1.14006052e-05,  1.12621892e-05,  1.96336841e-05,  7.02231409e-05,\n",
      "        3.14805584e-06,  1.69052441e-06,  1.91031213e-05, -2.96963954e-05,\n",
      "       -7.70766860e-07, -2.15022683e-05,  1.02805570e-05,  7.20958924e-05,\n",
      "        2.91288052e-06, -1.66028804e-05,  2.54510596e-05, -1.27927615e-05,\n",
      "        2.84544403e-05,  2.65348408e-05, -5.06919605e-05, -6.60067162e-05,\n",
      "       -2.59338012e-05,  2.41130401e-05, -1.23372502e-05, -4.44813049e-05,\n",
      "        4.98024338e-06, -8.08603800e-05, -9.91559227e-06,  5.67567258e-06,\n",
      "       -6.14908231e-06,  6.97669893e-05, -1.32145033e-07, -9.29816160e-05,\n",
      "        2.07700650e-05, -1.51225031e-04,  1.06592452e-04,  1.18219104e-05,\n",
      "       -1.16393585e-06,  5.76180992e-06,  1.08650156e-05,  1.32460937e-05,\n",
      "        3.33993885e-05, -4.84735665e-06,  1.91134150e-05, -2.51944348e-05,\n",
      "       -4.24259633e-05, -2.15505006e-05, -4.14605674e-05, -3.13819837e-05,\n",
      "       -1.40030943e-05, -9.01912063e-06, -1.88614449e-05,  3.36812263e-06,\n",
      "        2.64947685e-05, -4.01563157e-05,  2.03929194e-05,  6.76820055e-05,\n",
      "       -1.60844851e-04, -1.78299888e-06,  1.93203996e-05, -3.06587026e-05,\n",
      "        1.36832223e-05,  1.30191511e-05,  6.76222407e-06, -2.38218090e-05,\n",
      "        1.27634485e-06,  2.08942001e-05, -1.74280049e-05,  9.15522924e-06,\n",
      "        7.23614939e-05, -2.70180790e-05, -4.09097920e-05,  4.67903046e-05,\n",
      "        3.75076343e-05, -1.53865913e-05,  2.21933224e-05, -3.35855930e-06,\n",
      "        1.56162168e-05,  3.37267193e-05,  4.67273130e-05,  2.71167082e-05,\n",
      "       -3.86963438e-06, -1.93607366e-06, -1.74685192e-06, -3.48674512e-05,\n",
      "       -8.24630115e-06,  3.20545405e-06,  4.07685657e-05, -1.49273073e-05,\n",
      "       -1.61741355e-05, -1.19728866e-04, -3.26051959e-05,  7.86851306e-05,\n",
      "       -7.30953616e-05, -2.75946877e-05, -5.16152395e-05, -6.32114752e-05,\n",
      "        2.30198680e-06, -1.80238676e-05,  1.29313439e-05,  2.35703874e-06,\n",
      "        1.23043192e-05, -1.65563924e-05, -9.36712240e-06,  1.59040919e-05,\n",
      "        4.56472117e-05, -2.76821193e-05,  2.49239092e-05,  5.02966213e-06,\n",
      "       -4.23288257e-05, -1.67308790e-05,  2.72101679e-05,  4.57466704e-05,\n",
      "        7.99494956e-06, -1.88720660e-05,  3.94936797e-05,  1.82242511e-05,\n",
      "        1.52106222e-05, -5.38818022e-05,  5.23773015e-05, -6.49177946e-06,\n",
      "       -1.47370549e-04, -8.00209455e-06,  4.56312955e-05,  2.96771232e-05,\n",
      "        1.81361829e-05, -1.39235171e-05, -1.62669221e-05, -7.70771749e-06,\n",
      "        4.59725707e-05, -2.41112466e-05,  2.36258838e-05,  1.35306327e-04,\n",
      "        1.51823679e-05,  4.30950922e-06,  4.24966529e-05, -2.58476830e-05,\n",
      "       -2.31873491e-06, -4.29685970e-05,  2.40477175e-06,  6.89967928e-05,\n",
      "       -8.07614924e-06, -2.40303980e-05,  5.00197712e-05, -1.55866674e-05,\n",
      "        3.95289608e-05,  3.89940396e-06, -8.05796735e-05, -1.79242197e-05,\n",
      "       -2.62788526e-05,  3.02404369e-05, -3.00932115e-05, -5.63572648e-05,\n",
      "        1.80981510e-06, -1.12546426e-04, -1.53828587e-05, -2.93878838e-06,\n",
      "       -6.78043898e-06,  7.72505664e-05, -1.34196171e-06, -1.48092397e-04,\n",
      "        4.06655636e-05, -1.72506785e-04,  1.26741099e-04,  4.44805773e-05,\n",
      "       -4.69463193e-05,  1.29561322e-05,  7.35912681e-06,  5.13689411e-05,\n",
      "        1.67191174e-05, -7.36961010e-06, -2.21009032e-07, -1.41800283e-05,\n",
      "       -3.72008944e-05, -1.53450801e-05, -5.92183133e-05, -5.06114739e-05,\n",
      "       -2.32049842e-06,  1.45555077e-06, -1.75270980e-05,  7.58393435e-06,\n",
      "        3.36165540e-05, -5.90657037e-05,  2.81159009e-05,  6.69580622e-05,\n",
      "       -2.00637223e-04, -3.43056763e-06,  7.73676220e-06, -1.75222813e-05,\n",
      "       -1.19248371e-05,  1.49931184e-05,  2.20640832e-05, -2.59668795e-05,\n",
      "       -2.29297111e-05,  5.49576507e-05, -2.40431091e-05,  3.98712837e-05,\n",
      "        6.55364129e-05, -3.02125263e-05, -3.83918923e-05,  5.44097747e-05,\n",
      "        4.72050451e-05,  1.65507099e-05,  1.63916884e-05,  1.51987197e-05,\n",
      "        8.09004814e-06,  4.41954580e-05,  5.66676827e-05,  2.87145958e-05,\n",
      "       -2.33044266e-05, -1.96881501e-05, -1.37081024e-05, -7.39569077e-05,\n",
      "       -1.61685675e-05, -1.86368788e-06,  4.71008825e-05, -2.30022342e-05,\n",
      "       -4.29973807e-05, -1.85229903e-04, -3.59120822e-05,  9.61499027e-05,\n",
      "       -1.07203428e-04, -3.79122575e-05, -7.06464925e-05, -9.46015643e-05,\n",
      "        5.09742313e-06, -4.02132036e-06, -9.25490986e-06, -1.06254629e-05,\n",
      "        3.49527618e-05, -3.80849706e-05, -5.62272726e-06,  2.36080923e-05,\n",
      "        8.75225232e-05, -2.38668435e-05,  2.91681063e-05,  4.46425383e-06,\n",
      "       -7.77440582e-05, -1.41303190e-05,  5.73875695e-06,  6.57396231e-05,\n",
      "        1.67033686e-05, -2.27382880e-05,  6.14285163e-05,  2.93054245e-06,\n",
      "        1.95033936e-05, -8.47485790e-05,  6.92108151e-05, -7.26052531e-06,\n",
      "       -2.18372385e-04,  8.48131458e-06,  3.51255512e-05,  4.85970631e-05,\n",
      "        7.00887144e-02, -3.11476830e-02, -7.33920513e-03,  1.15989521e-02,\n",
      "       -6.12036698e-03,  3.61349322e-02,  6.18533604e-03, -2.49421876e-02,\n",
      "       -1.57304499e-02,  3.83400992e-02,  2.63627293e-03, -1.34485979e-02,\n",
      "       -2.87296227e-03,  1.93934422e-02, -3.60363498e-02, -3.69288772e-02,\n",
      "        3.67304496e-02,  2.47624815e-02,  1.27998674e-02,  2.74950303e-02,\n",
      "       -9.50261392e-03,  2.72873230e-02, -2.66510434e-02,  1.80765297e-02,\n",
      "        2.81279031e-02, -3.56345363e-02,  2.76560709e-02,  2.62640920e-02,\n",
      "       -4.95695043e-04,  2.74501480e-02, -5.45656271e-02, -9.81790945e-05,\n",
      "        4.67476845e-02,  6.20811209e-02, -9.52022616e-03,  2.97260545e-02,\n",
      "        4.66053328e-03, -7.52141625e-02, -3.85502353e-02,  1.80069264e-03,\n",
      "       -3.51394434e-03,  7.02487975e-02, -2.82401051e-02,  2.62992717e-02,\n",
      "       -1.05640078e-02, -1.54520106e-02,  5.21272719e-02, -2.09928453e-02,\n",
      "        1.85275190e-02,  1.36555266e-02,  3.11947800e-02,  4.47554141e-02,\n",
      "       -1.90415769e-03, -2.70528235e-02, -5.25643583e-03, -3.43010053e-02,\n",
      "        2.02010255e-02,  4.41105142e-02, -3.16924490e-02, -4.04536203e-02,\n",
      "        4.54020575e-02,  8.31268542e-03,  1.54346786e-02,  6.43147621e-03,\n",
      "        1.97345428e-02, -1.76894981e-02, -3.34588662e-02, -1.98038798e-02,\n",
      "       -2.37164572e-02,  6.08457206e-03, -9.20868851e-03, -7.50526860e-02,\n",
      "        5.02433293e-02, -1.66637488e-02,  1.86140109e-02,  2.60028280e-02,\n",
      "        2.63747051e-02,  8.91946256e-03, -5.32229319e-02,  2.40404587e-02,\n",
      "        1.94296297e-02,  8.79204366e-04, -2.87521258e-02,  8.13964847e-03,\n",
      "       -1.47178639e-02,  6.91508874e-03,  8.53476208e-03, -6.03680983e-02,\n",
      "       -1.62032656e-02, -1.38911735e-02,  5.11216000e-02,  4.77434183e-03,\n",
      "        1.41380504e-02,  6.42094687e-02,  2.79293731e-02,  7.11130798e-02,\n",
      "       -3.94093767e-02,  1.77322738e-02, -2.23726798e-02,  4.53469381e-02,\n",
      "        8.59516114e-03, -2.02164371e-02,  1.68765858e-02, -7.98271387e-04,\n",
      "        5.57026118e-02, -1.25774201e-02,  1.96815375e-02, -9.20386799e-03,\n",
      "        2.77697518e-02,  4.38992828e-02,  1.82443997e-04,  1.04173040e-03,\n",
      "       -1.48505699e-02,  2.15573199e-02, -9.94838076e-04, -3.25661674e-02,\n",
      "        4.12519416e-03, -4.91460226e-02, -1.85048059e-02, -1.03307404e-02,\n",
      "        4.43318952e-03,  3.04672513e-02, -8.11438635e-03,  1.84135549e-02,\n",
      "        7.53992349e-02, -1.28391879e-02,  6.87060365e-03,  2.85436749e-03,\n",
      "        4.72704596e-06, -2.05224642e-05, -1.21822832e-05, -8.75973910e-06,\n",
      "        1.48513091e-05,  1.21056146e-05,  3.21393090e-05,  8.52478843e-05,\n",
      "       -7.63891512e-06,  1.93584165e-05,  3.68356414e-05, -3.57396639e-05,\n",
      "        2.30481874e-08, -2.55033083e-05,  1.41429755e-05,  7.18222145e-05,\n",
      "        8.66765004e-06, -2.45930623e-05,  3.49784459e-05, -2.63473194e-05,\n",
      "        3.04261921e-05,  2.72617035e-05, -4.92240069e-05, -7.30498577e-05,\n",
      "       -4.01393117e-05,  2.56818603e-05, -1.66208374e-05, -4.94461019e-05,\n",
      "        7.77528840e-06, -9.17735306e-05, -5.21231914e-06,  9.82805432e-07,\n",
      "       -1.12508569e-05,  9.11052484e-05, -2.76252376e-06, -1.04088773e-04,\n",
      "        2.21554074e-05, -1.58111434e-04,  1.19098593e-04,  1.30926528e-05,\n",
      "        1.35615210e-06,  9.09498976e-06,  4.53320217e-06,  2.60897759e-05,\n",
      "        3.46774541e-05,  4.40971962e-06,  1.65622132e-05, -3.49540860e-05,\n",
      "       -4.77019130e-05, -1.28516403e-05, -4.33928617e-05, -3.84275772e-05,\n",
      "       -1.02395616e-05, -1.45926242e-06, -2.27266974e-05,  1.64279863e-05,\n",
      "        2.60925190e-05, -4.53716057e-05,  1.61301905e-05,  6.98910735e-05,\n",
      "       -1.70208310e-04,  1.63763616e-07,  2.01624607e-05, -2.99432322e-05,\n",
      "        1.51697514e-05,  1.13760807e-05,  5.05731032e-06, -3.88981462e-05,\n",
      "       -3.88725675e-06,  2.66817333e-05, -2.38223856e-05,  1.22099473e-05,\n",
      "        7.70226325e-05, -3.53493451e-05, -4.22105368e-05,  5.39036337e-05,\n",
      "        2.99354924e-05, -8.72029159e-06,  1.32847781e-05, -2.90398657e-06,\n",
      "        2.05778051e-05,  3.09879833e-05,  4.46196318e-05,  3.04302685e-05,\n",
      "       -1.20309051e-05, -7.17114381e-06,  2.36906635e-06, -5.10013961e-05,\n",
      "       -2.18123550e-05,  7.28320128e-06,  4.24651917e-05, -2.47093412e-05,\n",
      "       -1.27534440e-05, -1.50518390e-04, -3.32244272e-05,  8.78171122e-05,\n",
      "       -8.38761480e-05, -2.83504560e-05, -5.29509671e-05, -8.57476844e-05,\n",
      "       -7.30917236e-07, -1.58547518e-05,  1.41321152e-05,  2.66296865e-06,\n",
      "        2.23476327e-05, -1.89246421e-05, -8.38934284e-06,  1.21564235e-05,\n",
      "        5.44782379e-05, -2.54337265e-05,  2.94487072e-05,  3.12130646e-06,\n",
      "       -5.16872969e-05, -1.33557696e-05,  2.90569715e-05,  4.91394603e-05,\n",
      "        8.76048307e-06, -1.30382177e-05,  4.59206058e-05,  2.07583580e-05,\n",
      "        1.83681586e-05, -6.56651391e-05,  4.67723949e-05, -1.14600507e-05,\n",
      "       -1.80817486e-04, -6.62196771e-06,  4.16099429e-05,  3.41761443e-05],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(128, 10000), dtype=float32, numpy=\n",
      "array([[ 6.1452331e-05,  1.6764818e-04,  8.5234398e-04, ...,\n",
      "        -2.0533213e-07, -2.0532153e-07, -2.0675574e-07],\n",
      "       [-6.5334438e-04, -1.4142822e-03, -2.0218659e-03, ...,\n",
      "         3.2855714e-06,  3.2889300e-06,  3.2897851e-06],\n",
      "       [-6.0039217e-04,  7.8007282e-04, -5.7695934e-04, ...,\n",
      "         8.5578620e-08,  8.8649728e-08,  8.6885024e-08],\n",
      "       ...,\n",
      "       [-2.4790806e-04,  4.3643924e-04,  1.2964213e-03, ...,\n",
      "        -1.4338588e-06, -1.4333052e-06, -1.4358328e-06],\n",
      "       [ 9.5536967e-04,  3.3181414e-03,  2.2921097e-03, ...,\n",
      "        -3.7656114e-06, -3.7672160e-06, -3.7678769e-06],\n",
      "       [ 1.7109447e-03,  2.3047235e-03,  1.9412877e-03, ...,\n",
      "        -3.0626993e-06, -3.0656033e-06, -3.0677884e-06]], dtype=float32)>, <tf.Tensor: shape=(10000,), dtype=float32, numpy=\n",
      "array([-0.7979979 , -1.0313315 , -1.0313317 , ...,  0.00199928,\n",
      "        0.00199989,  0.00200043], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(grad_t_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "now, we have a list of tensors, t-list. We can use it to find clipped tensors. <b>clip_by_global_norm</b> clips values of multiple tensors by the ratio of the sum of their norms.\n",
    "\n",
    "<b>clip_by_global_norm</b> get <i>t-list</i> as input and returns 2 things:\n",
    "<ul>\n",
    "    <li>a list of clipped tensors, so called <i>list_clipped</i></li> \n",
    "    <li>the global norm (global_norm) of all tensors in t_list</li> \n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.framework.indexed_slices.IndexedSlices at 0x7f8d89516d10>,\n",
       " <tf.Tensor: shape=(200, 1024), dtype=float32, numpy=\n",
       " array([[ 2.91566948e-09, -1.06713912e-07, -6.02608566e-07, ...,\n",
       "          1.54288884e-07,  6.73811655e-08, -1.58908307e-07],\n",
       "        [ 2.82572671e-07, -3.25115167e-07,  9.03295785e-08, ...,\n",
       "         -2.08330050e-07,  1.09390115e-07, -6.53377526e-07],\n",
       "        [-6.47504407e-07,  1.00850954e-07,  5.39669259e-07, ...,\n",
       "          3.38197822e-07, -1.27664009e-07, -4.08838844e-07],\n",
       "        ...,\n",
       "        [-1.56591256e-07,  3.97478033e-08,  4.58209286e-07, ...,\n",
       "          1.15946968e-07,  3.30604308e-08, -2.67116349e-07],\n",
       "        [-4.37108952e-07, -5.22484243e-07,  4.42427222e-07, ...,\n",
       "          4.60641701e-07,  3.20872232e-07, -1.14021915e-07],\n",
       "        [-3.16484090e-07,  5.18981892e-07,  2.73768421e-08, ...,\n",
       "         -1.25576065e-07,  1.16187110e-07,  5.03616661e-07]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(256, 1024), dtype=float32, numpy=\n",
       " array([[ 6.86578971e-08, -1.06317756e-07,  1.57273718e-07, ...,\n",
       "          8.96402170e-08, -6.43866755e-08,  5.22124495e-08],\n",
       "        [-1.88319248e-07,  1.37902092e-07,  1.04651349e-07, ...,\n",
       "         -1.41432054e-07,  8.31990477e-08,  2.75974017e-08],\n",
       "        [-1.71781323e-07, -2.22011103e-08, -4.89744849e-08, ...,\n",
       "          1.55570774e-08, -1.48640069e-07,  4.62469139e-08],\n",
       "        ...,\n",
       "        [ 1.00457441e-07,  5.40705933e-08,  1.12140192e-07, ...,\n",
       "          1.12102271e-07, -7.32230490e-08,  2.53691553e-07],\n",
       "        [ 6.57814070e-09,  1.07933516e-07, -2.38810642e-08, ...,\n",
       "          1.62184399e-08, -2.14367226e-08,  1.32388507e-07],\n",
       "        [ 3.54502525e-08, -9.84170754e-08, -1.32598288e-08, ...,\n",
       "         -1.48308743e-07, -1.16296476e-07, -3.23217165e-07]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
       " array([ 1.0477739e-05,  7.6954202e-06,  1.7209029e-05, ...,\n",
       "        -1.5901034e-05, -1.0130257e-06,  1.9723371e-05], dtype=float32)>,\n",
       " <tf.Tensor: shape=(256, 512), dtype=float32, numpy=\n",
       " array([[ 3.46472603e-07, -1.99199803e-08,  5.81054351e-08, ...,\n",
       "         -2.95971461e-08, -3.50905154e-08, -1.09949823e-07],\n",
       "        [-1.55573034e-07,  5.86723203e-08,  2.28113265e-07, ...,\n",
       "         -1.16664090e-07, -1.88337395e-07,  1.55478659e-07],\n",
       "        [-2.24203418e-07,  9.90255700e-08, -2.12693152e-09, ...,\n",
       "          9.21307901e-08,  1.53319874e-07,  2.95831683e-07],\n",
       "        ...,\n",
       "        [ 1.35374975e-07,  3.90487173e-07,  1.04070175e-07, ...,\n",
       "          1.72491681e-07, -4.77408406e-08,  1.55023983e-07],\n",
       "        [-9.79586687e-08,  1.52375108e-07, -1.81927220e-07, ...,\n",
       "         -1.64495887e-07,  2.93793846e-07, -6.99883813e-08],\n",
       "        [-4.60568657e-07, -1.49461115e-07,  1.50361444e-07, ...,\n",
       "          6.92100741e-08, -2.10188631e-08,  1.16189725e-08]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(128, 512), dtype=float32, numpy=\n",
       " array([[ 5.57973351e-07,  8.21946031e-08, -1.07975865e-07, ...,\n",
       "         -1.33970545e-07, -1.01657299e-07,  5.32306004e-08],\n",
       "        [-3.51538922e-08, -2.12892701e-07,  1.56294160e-08, ...,\n",
       "         -2.86850650e-08, -1.22578598e-07, -1.18734427e-07],\n",
       "        [ 2.42569996e-07,  3.49666664e-07, -9.33414697e-08, ...,\n",
       "          8.89265834e-08, -1.99786058e-07, -1.18371034e-07],\n",
       "        ...,\n",
       "        [ 1.35862246e-08, -7.40085255e-08, -1.43901246e-08, ...,\n",
       "          1.57187927e-07, -9.99524161e-08,  3.80135923e-08],\n",
       "        [ 2.40179588e-07,  3.39011535e-07, -9.75441452e-08, ...,\n",
       "          9.87264848e-09, -1.21942080e-07, -6.39013962e-08],\n",
       "        [ 6.41360387e-08,  5.05267401e-08, -6.02255241e-08, ...,\n",
       "          1.60260072e-08, -1.37589609e-07,  2.52284764e-07]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(512,), dtype=float32, numpy=\n",
       " array([ 1.00473726e-05, -1.42586332e-05, -5.65112532e-06, -1.33186350e-05,\n",
       "         1.14006052e-05,  1.12621892e-05,  1.96336841e-05,  7.02231409e-05,\n",
       "         3.14805584e-06,  1.69052441e-06,  1.91031213e-05, -2.96963954e-05,\n",
       "        -7.70766860e-07, -2.15022683e-05,  1.02805570e-05,  7.20958924e-05,\n",
       "         2.91288052e-06, -1.66028804e-05,  2.54510596e-05, -1.27927615e-05,\n",
       "         2.84544403e-05,  2.65348408e-05, -5.06919605e-05, -6.60067162e-05,\n",
       "        -2.59338012e-05,  2.41130401e-05, -1.23372502e-05, -4.44813049e-05,\n",
       "         4.98024338e-06, -8.08603800e-05, -9.91559227e-06,  5.67567258e-06,\n",
       "        -6.14908231e-06,  6.97669893e-05, -1.32145033e-07, -9.29816160e-05,\n",
       "         2.07700650e-05, -1.51225031e-04,  1.06592452e-04,  1.18219104e-05,\n",
       "        -1.16393585e-06,  5.76180992e-06,  1.08650156e-05,  1.32460937e-05,\n",
       "         3.33993885e-05, -4.84735665e-06,  1.91134150e-05, -2.51944348e-05,\n",
       "        -4.24259633e-05, -2.15505006e-05, -4.14605674e-05, -3.13819837e-05,\n",
       "        -1.40030943e-05, -9.01912063e-06, -1.88614449e-05,  3.36812263e-06,\n",
       "         2.64947685e-05, -4.01563157e-05,  2.03929194e-05,  6.76820055e-05,\n",
       "        -1.60844851e-04, -1.78299888e-06,  1.93203996e-05, -3.06587026e-05,\n",
       "         1.36832223e-05,  1.30191511e-05,  6.76222407e-06, -2.38218090e-05,\n",
       "         1.27634485e-06,  2.08942001e-05, -1.74280049e-05,  9.15522924e-06,\n",
       "         7.23614939e-05, -2.70180790e-05, -4.09097920e-05,  4.67903046e-05,\n",
       "         3.75076343e-05, -1.53865913e-05,  2.21933224e-05, -3.35855930e-06,\n",
       "         1.56162168e-05,  3.37267193e-05,  4.67273130e-05,  2.71167082e-05,\n",
       "        -3.86963438e-06, -1.93607366e-06, -1.74685192e-06, -3.48674512e-05,\n",
       "        -8.24630115e-06,  3.20545405e-06,  4.07685657e-05, -1.49273073e-05,\n",
       "        -1.61741355e-05, -1.19728866e-04, -3.26051959e-05,  7.86851306e-05,\n",
       "        -7.30953616e-05, -2.75946877e-05, -5.16152395e-05, -6.32114752e-05,\n",
       "         2.30198680e-06, -1.80238676e-05,  1.29313439e-05,  2.35703874e-06,\n",
       "         1.23043192e-05, -1.65563924e-05, -9.36712240e-06,  1.59040919e-05,\n",
       "         4.56472117e-05, -2.76821193e-05,  2.49239092e-05,  5.02966213e-06,\n",
       "        -4.23288257e-05, -1.67308790e-05,  2.72101679e-05,  4.57466704e-05,\n",
       "         7.99494956e-06, -1.88720660e-05,  3.94936797e-05,  1.82242511e-05,\n",
       "         1.52106222e-05, -5.38818022e-05,  5.23773015e-05, -6.49177946e-06,\n",
       "        -1.47370549e-04, -8.00209455e-06,  4.56312955e-05,  2.96771232e-05,\n",
       "         1.81361829e-05, -1.39235171e-05, -1.62669221e-05, -7.70771749e-06,\n",
       "         4.59725707e-05, -2.41112466e-05,  2.36258838e-05,  1.35306327e-04,\n",
       "         1.51823679e-05,  4.30950922e-06,  4.24966529e-05, -2.58476830e-05,\n",
       "        -2.31873491e-06, -4.29685970e-05,  2.40477175e-06,  6.89967928e-05,\n",
       "        -8.07614924e-06, -2.40303980e-05,  5.00197712e-05, -1.55866674e-05,\n",
       "         3.95289608e-05,  3.89940396e-06, -8.05796735e-05, -1.79242197e-05,\n",
       "        -2.62788526e-05,  3.02404369e-05, -3.00932115e-05, -5.63572648e-05,\n",
       "         1.80981510e-06, -1.12546426e-04, -1.53828587e-05, -2.93878838e-06,\n",
       "        -6.78043898e-06,  7.72505664e-05, -1.34196171e-06, -1.48092397e-04,\n",
       "         4.06655636e-05, -1.72506785e-04,  1.26741099e-04,  4.44805773e-05,\n",
       "        -4.69463193e-05,  1.29561322e-05,  7.35912681e-06,  5.13689411e-05,\n",
       "         1.67191174e-05, -7.36961010e-06, -2.21009032e-07, -1.41800283e-05,\n",
       "        -3.72008944e-05, -1.53450801e-05, -5.92183133e-05, -5.06114739e-05,\n",
       "        -2.32049842e-06,  1.45555077e-06, -1.75270980e-05,  7.58393435e-06,\n",
       "         3.36165540e-05, -5.90657037e-05,  2.81159009e-05,  6.69580622e-05,\n",
       "        -2.00637223e-04, -3.43056763e-06,  7.73676220e-06, -1.75222813e-05,\n",
       "        -1.19248371e-05,  1.49931184e-05,  2.20640832e-05, -2.59668795e-05,\n",
       "        -2.29297111e-05,  5.49576507e-05, -2.40431091e-05,  3.98712837e-05,\n",
       "         6.55364129e-05, -3.02125263e-05, -3.83918923e-05,  5.44097747e-05,\n",
       "         4.72050451e-05,  1.65507099e-05,  1.63916884e-05,  1.51987197e-05,\n",
       "         8.09004814e-06,  4.41954580e-05,  5.66676827e-05,  2.87145958e-05,\n",
       "        -2.33044266e-05, -1.96881501e-05, -1.37081024e-05, -7.39569077e-05,\n",
       "        -1.61685675e-05, -1.86368788e-06,  4.71008825e-05, -2.30022342e-05,\n",
       "        -4.29973807e-05, -1.85229903e-04, -3.59120822e-05,  9.61499027e-05,\n",
       "        -1.07203428e-04, -3.79122575e-05, -7.06464925e-05, -9.46015643e-05,\n",
       "         5.09742313e-06, -4.02132036e-06, -9.25490986e-06, -1.06254629e-05,\n",
       "         3.49527618e-05, -3.80849706e-05, -5.62272726e-06,  2.36080923e-05,\n",
       "         8.75225232e-05, -2.38668435e-05,  2.91681063e-05,  4.46425383e-06,\n",
       "        -7.77440582e-05, -1.41303190e-05,  5.73875695e-06,  6.57396231e-05,\n",
       "         1.67033686e-05, -2.27382880e-05,  6.14285163e-05,  2.93054245e-06,\n",
       "         1.95033936e-05, -8.47485790e-05,  6.92108151e-05, -7.26052531e-06,\n",
       "        -2.18372385e-04,  8.48131458e-06,  3.51255512e-05,  4.85970631e-05,\n",
       "         7.00887144e-02, -3.11476830e-02, -7.33920513e-03,  1.15989521e-02,\n",
       "        -6.12036698e-03,  3.61349322e-02,  6.18533604e-03, -2.49421876e-02,\n",
       "        -1.57304499e-02,  3.83400992e-02,  2.63627293e-03, -1.34485979e-02,\n",
       "        -2.87296227e-03,  1.93934422e-02, -3.60363498e-02, -3.69288772e-02,\n",
       "         3.67304496e-02,  2.47624815e-02,  1.27998674e-02,  2.74950303e-02,\n",
       "        -9.50261392e-03,  2.72873230e-02, -2.66510434e-02,  1.80765297e-02,\n",
       "         2.81279031e-02, -3.56345363e-02,  2.76560709e-02,  2.62640920e-02,\n",
       "        -4.95695043e-04,  2.74501480e-02, -5.45656271e-02, -9.81790945e-05,\n",
       "         4.67476845e-02,  6.20811209e-02, -9.52022616e-03,  2.97260545e-02,\n",
       "         4.66053328e-03, -7.52141625e-02, -3.85502353e-02,  1.80069264e-03,\n",
       "        -3.51394434e-03,  7.02487975e-02, -2.82401051e-02,  2.62992717e-02,\n",
       "        -1.05640078e-02, -1.54520106e-02,  5.21272719e-02, -2.09928453e-02,\n",
       "         1.85275190e-02,  1.36555266e-02,  3.11947800e-02,  4.47554141e-02,\n",
       "        -1.90415769e-03, -2.70528235e-02, -5.25643583e-03, -3.43010053e-02,\n",
       "         2.02010255e-02,  4.41105142e-02, -3.16924490e-02, -4.04536203e-02,\n",
       "         4.54020575e-02,  8.31268542e-03,  1.54346786e-02,  6.43147621e-03,\n",
       "         1.97345428e-02, -1.76894981e-02, -3.34588662e-02, -1.98038798e-02,\n",
       "        -2.37164572e-02,  6.08457206e-03, -9.20868851e-03, -7.50526860e-02,\n",
       "         5.02433293e-02, -1.66637488e-02,  1.86140109e-02,  2.60028280e-02,\n",
       "         2.63747051e-02,  8.91946256e-03, -5.32229319e-02,  2.40404587e-02,\n",
       "         1.94296297e-02,  8.79204366e-04, -2.87521258e-02,  8.13964847e-03,\n",
       "        -1.47178639e-02,  6.91508874e-03,  8.53476208e-03, -6.03680983e-02,\n",
       "        -1.62032656e-02, -1.38911735e-02,  5.11216000e-02,  4.77434183e-03,\n",
       "         1.41380504e-02,  6.42094687e-02,  2.79293731e-02,  7.11130798e-02,\n",
       "        -3.94093767e-02,  1.77322738e-02, -2.23726798e-02,  4.53469381e-02,\n",
       "         8.59516114e-03, -2.02164371e-02,  1.68765858e-02, -7.98271387e-04,\n",
       "         5.57026118e-02, -1.25774201e-02,  1.96815375e-02, -9.20386799e-03,\n",
       "         2.77697518e-02,  4.38992828e-02,  1.82443997e-04,  1.04173040e-03,\n",
       "        -1.48505699e-02,  2.15573199e-02, -9.94838076e-04, -3.25661674e-02,\n",
       "         4.12519416e-03, -4.91460226e-02, -1.85048059e-02, -1.03307404e-02,\n",
       "         4.43318952e-03,  3.04672513e-02, -8.11438635e-03,  1.84135549e-02,\n",
       "         7.53992349e-02, -1.28391879e-02,  6.87060365e-03,  2.85436749e-03,\n",
       "         4.72704596e-06, -2.05224642e-05, -1.21822832e-05, -8.75973910e-06,\n",
       "         1.48513091e-05,  1.21056146e-05,  3.21393090e-05,  8.52478843e-05,\n",
       "        -7.63891512e-06,  1.93584165e-05,  3.68356414e-05, -3.57396639e-05,\n",
       "         2.30481874e-08, -2.55033083e-05,  1.41429755e-05,  7.18222145e-05,\n",
       "         8.66765004e-06, -2.45930623e-05,  3.49784459e-05, -2.63473194e-05,\n",
       "         3.04261921e-05,  2.72617035e-05, -4.92240069e-05, -7.30498577e-05,\n",
       "        -4.01393117e-05,  2.56818603e-05, -1.66208374e-05, -4.94461019e-05,\n",
       "         7.77528840e-06, -9.17735306e-05, -5.21231914e-06,  9.82805432e-07,\n",
       "        -1.12508569e-05,  9.11052484e-05, -2.76252376e-06, -1.04088773e-04,\n",
       "         2.21554074e-05, -1.58111434e-04,  1.19098593e-04,  1.30926528e-05,\n",
       "         1.35615210e-06,  9.09498976e-06,  4.53320217e-06,  2.60897759e-05,\n",
       "         3.46774541e-05,  4.40971962e-06,  1.65622132e-05, -3.49540860e-05,\n",
       "        -4.77019130e-05, -1.28516403e-05, -4.33928617e-05, -3.84275772e-05,\n",
       "        -1.02395616e-05, -1.45926242e-06, -2.27266974e-05,  1.64279863e-05,\n",
       "         2.60925190e-05, -4.53716057e-05,  1.61301905e-05,  6.98910735e-05,\n",
       "        -1.70208310e-04,  1.63763616e-07,  2.01624607e-05, -2.99432322e-05,\n",
       "         1.51697514e-05,  1.13760807e-05,  5.05731032e-06, -3.88981462e-05,\n",
       "        -3.88725675e-06,  2.66817333e-05, -2.38223856e-05,  1.22099473e-05,\n",
       "         7.70226325e-05, -3.53493451e-05, -4.22105368e-05,  5.39036337e-05,\n",
       "         2.99354924e-05, -8.72029159e-06,  1.32847781e-05, -2.90398657e-06,\n",
       "         2.05778051e-05,  3.09879833e-05,  4.46196318e-05,  3.04302685e-05,\n",
       "        -1.20309051e-05, -7.17114381e-06,  2.36906635e-06, -5.10013961e-05,\n",
       "        -2.18123550e-05,  7.28320128e-06,  4.24651917e-05, -2.47093412e-05,\n",
       "        -1.27534440e-05, -1.50518390e-04, -3.32244272e-05,  8.78171122e-05,\n",
       "        -8.38761480e-05, -2.83504560e-05, -5.29509671e-05, -8.57476844e-05,\n",
       "        -7.30917236e-07, -1.58547518e-05,  1.41321152e-05,  2.66296865e-06,\n",
       "         2.23476327e-05, -1.89246421e-05, -8.38934284e-06,  1.21564235e-05,\n",
       "         5.44782379e-05, -2.54337265e-05,  2.94487072e-05,  3.12130646e-06,\n",
       "        -5.16872969e-05, -1.33557696e-05,  2.90569715e-05,  4.91394603e-05,\n",
       "         8.76048307e-06, -1.30382177e-05,  4.59206058e-05,  2.07583580e-05,\n",
       "         1.83681586e-05, -6.56651391e-05,  4.67723949e-05, -1.14600507e-05,\n",
       "        -1.80817486e-04, -6.62196771e-06,  4.16099429e-05,  3.41761443e-05],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(128, 10000), dtype=float32, numpy=\n",
       " array([[ 6.1452331e-05,  1.6764818e-04,  8.5234398e-04, ...,\n",
       "         -2.0533213e-07, -2.0532153e-07, -2.0675574e-07],\n",
       "        [-6.5334438e-04, -1.4142822e-03, -2.0218659e-03, ...,\n",
       "          3.2855714e-06,  3.2889300e-06,  3.2897851e-06],\n",
       "        [-6.0039217e-04,  7.8007282e-04, -5.7695934e-04, ...,\n",
       "          8.5578620e-08,  8.8649728e-08,  8.6885024e-08],\n",
       "        ...,\n",
       "        [-2.4790806e-04,  4.3643924e-04,  1.2964213e-03, ...,\n",
       "         -1.4338588e-06, -1.4333052e-06, -1.4358328e-06],\n",
       "        [ 9.5536967e-04,  3.3181414e-03,  2.2921097e-03, ...,\n",
       "         -3.7656114e-06, -3.7672160e-06, -3.7678769e-06],\n",
       "        [ 1.7109447e-03,  2.3047235e-03,  1.9412877e-03, ...,\n",
       "         -3.0626993e-06, -3.0656033e-06, -3.0677884e-06]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10000,), dtype=float32, numpy=\n",
       " array([-0.7979979 , -1.0313315 , -1.0313317 , ...,  0.00199928,\n",
       "         0.00199989,  0.00200043], dtype=float32)>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the gradient clipping threshold\n",
    "grads, _ = tf.clip_by_global_norm(grad_t_list, max_grad_norm)\n",
    "grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 4.Apply the optimizer to the variables/gradients tuple. </h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training TensorFlow Operation through our optimizer\n",
    "train_op = optimizer.apply_gradients(zip(grads, tvars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ltsm\"></a>\n",
    "<h2>LSTM</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learned how the model is build step by step. Now, let's then create a Class that represents our model. This class needs a few things:\n",
    "<ul>\n",
    "    <li>We have to create the model in accordance with our defined hyperparameters</li>\n",
    "    <li>We have to create the LSTM cell structure and connect them with our RNN structure</li>\n",
    "    <li>We have to create the word embeddings and point them to the input data</li>\n",
    "    <li>We have to create the input structure for our RNN</li>\n",
    "    <li>We need to create a logistic structure to return the probability of our words</li>\n",
    "    <li>We need to create the loss and cost functions for our optimizer to work, and then create the optimizer</li>\n",
    "    <li>And finally, we need to create a training operation that can be run to actually train our model</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PTBModel(object):\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        ######################################\n",
    "        # Setting parameters for ease of use #\n",
    "        ######################################\n",
    "        self.batch_size = batch_size\n",
    "        self.num_steps = num_steps\n",
    "        self.hidden_size_l1 = hidden_size_l1\n",
    "        self.hidden_size_l2 = hidden_size_l2\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embeding_vector_size = embeding_vector_size\n",
    "        # Create a variable for the learning rate\n",
    "        self._lr = 1.0\n",
    "        \n",
    "        ###############################################################################\n",
    "        # Initializing the model using keras Sequential API  #\n",
    "        ###############################################################################\n",
    "        \n",
    "        self._model = tf.keras.models.Sequential()\n",
    "        \n",
    "        ####################################################################\n",
    "        # Creating the word embeddings layer and adding it to the sequence #\n",
    "        ####################################################################\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            # Create the embeddings for our input data. Size is hidden size.\n",
    "            self._embedding_layer = tf.keras.layers.Embedding(self.vocab_size, self.embeding_vector_size,batch_input_shape=(self.batch_size, self.num_steps),trainable=True,name=\"embedding_vocab\")  #[10000x200]\n",
    "            self._model.add(self._embedding_layer)\n",
    "            \n",
    "\n",
    "        ##########################################################################\n",
    "        # Creating the LSTM cell structure and connect it with the RNN structure #\n",
    "        ##########################################################################\n",
    "        # Create the LSTM Cells. \n",
    "        # This creates only the structure for the LSTM and has to be associated with a RNN unit still.\n",
    "        # The argument  of LSTMCell is size of hidden layer, that is, the number of hidden units of the LSTM (inside A). \n",
    "        # LSTM cell processes one word at a time and computes probabilities of the possible continuations of the sentence.\n",
    "        lstm_cell_l1 = tf.keras.layers.LSTMCell(hidden_size_l1)\n",
    "        lstm_cell_l2 = tf.keras.layers.LSTMCell(hidden_size_l2)\n",
    "        \n",
    "\n",
    "        \n",
    "        # By taking in the LSTM cells as parameters, the StackedRNNCells function junctions the LSTM units to the RNN units.\n",
    "        # RNN cell composed sequentially of stacked simple cells.\n",
    "        stacked_lstm = tf.keras.layers.StackedRNNCells([lstm_cell_l1, lstm_cell_l2])\n",
    "\n",
    "        \n",
    "        ############################################\n",
    "        # Creating the input structure for our RNN #\n",
    "        ############################################\n",
    "        # Input structure is 20x[30x200]\n",
    "        # Considering each word is represended by a 200 dimentional vector, and we have 30 batchs, we create 30 word-vectors of size [30xx2000]\n",
    "        # The input structure is fed from the embeddings, which are filled in by the input data\n",
    "        # Feeding a batch of b sentences to a RNN:\n",
    "        # In step 1,  first word of each of the b sentences (in a batch) is input in parallel.  \n",
    "        # In step 2,  second word of each of the b sentences is input in parallel. \n",
    "        # The parallelism is only for efficiency.  \n",
    "        # Each sentence in a batch is handled in parallel, but the network sees one word of a sentence at a time and does the computations accordingly. \n",
    "        # All the computations involving the words of all sentences in a batch at a given time step are done in parallel. \n",
    "\n",
    "        ########################################################################################################\n",
    "        # Instantiating our RNN model and setting stateful to True to feed forward the state to the next layer #\n",
    "        ########################################################################################################\n",
    "        \n",
    "        self._RNNlayer  =  tf.keras.layers.RNN(stacked_lstm,[batch_size, num_steps],return_state=False,stateful=True,trainable=True)\n",
    "        \n",
    "        # Define the initial state, i.e., the model state for the very first data point\n",
    "        # It initialize the state of the LSTM memory. The memory state of the network is initialized with a vector of zeros and gets updated after reading each word.\n",
    "        self._initial_state = tf.Variable(tf.zeros([batch_size,embeding_vector_size]),trainable=False)\n",
    "        self._RNNlayer.inital_state = self._initial_state\n",
    "    \n",
    "        ############################################\n",
    "        # Adding RNN layer to keras sequential API #\n",
    "        ############################################        \n",
    "        self._model.add(self._RNNlayer)\n",
    "        \n",
    "        #self._model.add(tf.keras.layers.LSTM(hidden_size_l1,return_sequences=True,stateful=True))\n",
    "        #self._model.add(tf.keras.layers.LSTM(hidden_size_l2,return_sequences=True))\n",
    "        \n",
    "        \n",
    "        ####################################################################################################\n",
    "        # Instantiating a Dense layer that connects the output to the vocab_size  and adding layer to model#\n",
    "        ####################################################################################################\n",
    "        self._dense = tf.keras.layers.Dense(self.vocab_size)\n",
    "        self._model.add(self._dense)\n",
    " \n",
    "        \n",
    "        ####################################################################################################\n",
    "        # Adding softmax activation layer and deriving probability to each class and adding layer to model #\n",
    "        ####################################################################################################\n",
    "        self._activation = tf.keras.layers.Activation('softmax')\n",
    "        self._model.add(self._activation)\n",
    "\n",
    "        ##########################################################\n",
    "        # Instantiating the stochastic gradient decent optimizer #\n",
    "        ########################################################## \n",
    "        self._optimizer = tf.keras.optimizers.SGD(learning_rate=self._lr, clipnorm=max_grad_norm)\n",
    "        \n",
    "        \n",
    "        ##############################################################################\n",
    "        # Compiling and summarizing the model stacked using the keras sequential API #\n",
    "        ##############################################################################\n",
    "        self._model.compile(loss=self.crossentropy, optimizer=self._optimizer)\n",
    "        self._model.summary()\n",
    "\n",
    "\n",
    "    def crossentropy(self,y_true, y_pred):\n",
    "        return tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "\n",
    "    def train_batch(self,_input_data,_targets):\n",
    "        #################################################\n",
    "        # Creating the Training Operation for our Model #\n",
    "        #################################################\n",
    "        # Create a variable for the learning rate\n",
    "        self._lr = tf.Variable(0.0, trainable=False)\n",
    "        # Get all TensorFlow variables marked as \"trainable\" (i.e. all of them except _lr, which we just created)\n",
    "        tvars = self._model.trainable_variables\n",
    "        # Define the gradient clipping threshold\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass.\n",
    "            output_words_prob = self._model(_input_data)\n",
    "            # Loss value for this batch.\n",
    "            loss  = self.crossentropy(_targets, output_words_prob)\n",
    "            # average across batch and reduce sum\n",
    "            cost = tf.reduce_sum(loss/ self.batch_size)\n",
    "        # Get gradients of loss wrt the trainable variables.\n",
    "        grad_t_list = tape.gradient(cost, tvars)\n",
    "        # Define the gradient clipping threshold\n",
    "        grads, _ = tf.clip_by_global_norm(grad_t_list, max_grad_norm)\n",
    "        # Create the training TensorFlow Operation through our optimizer\n",
    "        train_op = self._optimizer.apply_gradients(zip(grads, tvars))\n",
    "        return cost\n",
    "        \n",
    "    def test_batch(self,_input_data,_targets):\n",
    "        #################################################\n",
    "        # Creating the Testing Operation for our Model #\n",
    "        #################################################\n",
    "        output_words_prob = self._model(_input_data)\n",
    "        loss  = self.crossentropy(_targets, output_words_prob)\n",
    "        # average across batch and reduce sum\n",
    "        cost = tf.reduce_sum(loss/ self.batch_size)\n",
    "        #Prediction\n",
    "        words_test = np.argmax(output_words_prob[:,0:num_steps], axis=2)\n",
    "        words_target = _targets[:]\n",
    "        return cost, words_test, words_target\n",
    "    \n",
    "    @classmethod\n",
    "    def instance(cls) : \n",
    "        return PTBModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that, the actual structure of our Recurrent Neural Network with Long Short-Term Memory is finished. What remains for us to do is to actually create the methods to run through time -- that is, the <code>run_epoch</code> method to be run at each epoch and a <code>main</code> script which ties all of this together.\n",
    "\n",
    "What our <code>run_epoch</code> method should do is take our input data and feed it to the relevant operations. This will return at the very least the current result for the cost function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# run_one_epoch takes as parameters  the model instance, the data to be fed, training or testing mode and verbose info #\n",
    "########################################################################################################################\n",
    "def run_one_epoch(m, data,is_training=True,verbose=False):\n",
    "\n",
    "    #Define the epoch size based on the length of the data, batch size and the number of steps\n",
    "    epoch_size = ((len(data) // m.batch_size) - 1) // m.num_steps\n",
    "    start_time = time.time()\n",
    "    costs = 0.\n",
    "    iters = 0\n",
    "    \n",
    "    m._model.reset_states()\n",
    "    \n",
    "    #For each step and data point\n",
    "    for step, (x, y) in enumerate(ptb_iterator(data, m.batch_size, m.num_steps)):\n",
    "        \n",
    "        #Evaluate and return cost, state by running cost, final_state and the function passed as parameter\n",
    "        #y = tf.keras.utils.to_categorical(y, num_classes=vocab_size)\n",
    "        if is_training : \n",
    "            loss =  m.train_batch(x, y)\n",
    "            words_test = 0\n",
    "            words_target = 0\n",
    "        else :\n",
    "            loss, words_test, words_target = m.test_batch(x, y)\n",
    "\n",
    "        #Add returned cost to costs (which keeps track of the total costs for this epoch)\n",
    "        costs += loss\n",
    "        \n",
    "        #Add number of steps to iteration counter\n",
    "        iters += m.num_steps\n",
    "\n",
    "        if verbose and step % (epoch_size // 10) == 10:\n",
    "            print(\"Itr %d of %d, perplexity: %.3f speed: %.0f wps\" % (step , epoch_size, np.exp(costs / iters), iters * m.batch_size / (time.time() - start_time)))\n",
    "\n",
    "    # Returns the Perplexity rating for us to keep track of how the model is evolving\n",
    "    return np.exp(costs / iters), words_test, words_target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create the <code>main</code> method to tie everything together. The code here reads the data from the directory, using the <code>reader</code> helper module, and then trains and evaluates the model on both a testing and a validating subset of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the data and separates it into training data, validation data and testing data\n",
    "raw_data = ptb_raw_data(data_dir)\n",
    "train_data, valid_data, test_data, _, _ = raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_vocab (Embedding)  (30, 20, 200)            2000000   \n",
      "                                                                 \n",
      " rnn_1 (RNN)                 (30, 20, 128)             671088    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (30, 20, 10000)           1290000   \n",
      "                                                                 \n",
      " activation_1 (Activation)   (30, 20, 10000)           0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,961,088\n",
      "Trainable params: 3,955,088\n",
      "Non-trainable params: 6,000\n",
      "_________________________________________________________________\n",
      "Epoch 1 : Learning rate: 1.000\n",
      "Itr 10 of 1549, perplexity: 4736.563 speed: 925 wps\n",
      "Itr 164 of 1549, perplexity: 1104.598 speed: 974 wps\n",
      "Itr 318 of 1549, perplexity: 847.148 speed: 978 wps\n",
      "Itr 472 of 1549, perplexity: 699.689 speed: 982 wps\n",
      "Itr 626 of 1549, perplexity: 594.338 speed: 981 wps\n",
      "Itr 780 of 1549, perplexity: 527.151 speed: 983 wps\n",
      "Itr 934 of 1549, perplexity: 475.471 speed: 982 wps\n",
      "Itr 1088 of 1549, perplexity: 436.613 speed: 979 wps\n",
      "Itr 1242 of 1549, perplexity: 406.859 speed: 977 wps\n",
      "Itr 1396 of 1549, perplexity: 379.088 speed: 975 wps\n",
      "Epoch 1 : Train Perplexity: 357.202\n",
      "Epoch 1 : Valid Perplexity: 210.974\n",
      "Epoch 2 : Learning rate: 1.000\n",
      "Itr 10 of 1549, perplexity: 238.155 speed: 999 wps\n",
      "Itr 164 of 1549, perplexity: 210.844 speed: 966 wps\n",
      "Itr 318 of 1549, perplexity: 202.091 speed: 974 wps\n",
      "Itr 472 of 1549, perplexity: 193.793 speed: 981 wps\n",
      "Itr 626 of 1549, perplexity: 184.942 speed: 979 wps\n",
      "Itr 780 of 1549, perplexity: 181.265 speed: 982 wps\n",
      "Itr 934 of 1549, perplexity: 177.283 speed: 980 wps\n",
      "Itr 1088 of 1549, perplexity: 173.951 speed: 980 wps\n",
      "Itr 1242 of 1549, perplexity: 171.494 speed: 977 wps\n",
      "Itr 1396 of 1549, perplexity: 167.501 speed: 978 wps\n",
      "Epoch 2 : Train Perplexity: 164.696\n",
      "Epoch 2 : Valid Perplexity: 161.340\n",
      "Epoch 3 : Learning rate: 1.000\n",
      "Itr 10 of 1549, perplexity: 162.785 speed: 997 wps\n",
      "Itr 164 of 1549, perplexity: 147.735 speed: 974 wps\n",
      "Itr 318 of 1549, perplexity: 144.166 speed: 986 wps\n",
      "Itr 472 of 1549, perplexity: 139.445 speed: 985 wps\n",
      "Itr 626 of 1549, perplexity: 134.476 speed: 983 wps\n",
      "Itr 780 of 1549, perplexity: 133.268 speed: 980 wps\n",
      "Itr 934 of 1549, perplexity: 131.615 speed: 980 wps\n",
      "Itr 1088 of 1549, perplexity: 130.146 speed: 981 wps\n",
      "Itr 1242 of 1549, perplexity: 129.290 speed: 981 wps\n",
      "Itr 1396 of 1549, perplexity: 126.969 speed: 981 wps\n",
      "Epoch 3 : Train Perplexity: 125.713\n",
      "Epoch 3 : Valid Perplexity: 144.846\n",
      "Epoch 4 : Learning rate: 1.000\n",
      "Itr 10 of 1549, perplexity: 130.192 speed: 1012 wps\n",
      "Itr 164 of 1549, perplexity: 120.673 speed: 965 wps\n",
      "Itr 318 of 1549, perplexity: 118.569 speed: 983 wps\n",
      "Itr 472 of 1549, perplexity: 115.102 speed: 983 wps\n",
      "Itr 626 of 1549, perplexity: 111.354 speed: 986 wps\n",
      "Itr 780 of 1549, perplexity: 110.957 speed: 984 wps\n",
      "Itr 934 of 1549, perplexity: 110.018 speed: 983 wps\n",
      "Itr 1088 of 1549, perplexity: 109.149 speed: 980 wps\n",
      "Itr 1242 of 1549, perplexity: 108.767 speed: 981 wps\n",
      "Itr 1396 of 1549, perplexity: 107.068 speed: 981 wps\n",
      "Epoch 4 : Train Perplexity: 106.359\n",
      "Epoch 4 : Valid Perplexity: 137.115\n",
      "Epoch 5 : Learning rate: 1.000\n",
      "Itr 10 of 1549, perplexity: 112.398 speed: 1002 wps\n",
      "Itr 164 of 1549, perplexity: 105.229 speed: 994 wps\n",
      "Itr 318 of 1549, perplexity: 103.928 speed: 989 wps\n",
      "Itr 472 of 1549, perplexity: 101.061 speed: 986 wps\n",
      "Itr 626 of 1549, perplexity: 97.972 speed: 989 wps\n",
      "Itr 780 of 1549, perplexity: 97.797 speed: 985 wps\n",
      "Itr 934 of 1549, perplexity: 97.134 speed: 986 wps\n",
      "Itr 1088 of 1549, perplexity: 96.534 speed: 983 wps\n",
      "Itr 1242 of 1549, perplexity: 96.390 speed: 983 wps\n",
      "Itr 1396 of 1549, perplexity: 95.046 speed: 982 wps\n",
      "Epoch 5 : Train Perplexity: 94.506\n",
      "Epoch 5 : Valid Perplexity: 133.283\n",
      "Epoch 6 : Learning rate: 0.500\n",
      "Itr 10 of 1549, perplexity: 99.889 speed: 982 wps\n",
      "Itr 164 of 1549, perplexity: 91.377 speed: 992 wps\n",
      "Itr 318 of 1549, perplexity: 89.029 speed: 982 wps\n",
      "Itr 472 of 1549, perplexity: 85.716 speed: 986 wps\n",
      "Itr 626 of 1549, perplexity: 82.176 speed: 983 wps\n",
      "Itr 780 of 1549, perplexity: 81.400 speed: 983 wps\n",
      "Itr 934 of 1549, perplexity: 80.226 speed: 979 wps\n",
      "Itr 1088 of 1549, perplexity: 79.183 speed: 981 wps\n",
      "Itr 1242 of 1549, perplexity: 78.481 speed: 982 wps\n",
      "Itr 1396 of 1549, perplexity: 76.816 speed: 981 wps\n",
      "Epoch 6 : Train Perplexity: 75.820\n",
      "Epoch 6 : Valid Perplexity: 124.938\n",
      "Epoch 7 : Learning rate: 0.250\n",
      "Itr 10 of 1549, perplexity: 83.352 speed: 1026 wps\n",
      "Itr 164 of 1549, perplexity: 78.537 speed: 1003 wps\n",
      "Itr 318 of 1549, perplexity: 76.672 speed: 992 wps\n",
      "Itr 472 of 1549, perplexity: 73.847 speed: 991 wps\n",
      "Itr 626 of 1549, perplexity: 70.683 speed: 986 wps\n",
      "Itr 780 of 1549, perplexity: 69.880 speed: 986 wps\n",
      "Itr 934 of 1549, perplexity: 68.777 speed: 985 wps\n",
      "Itr 1088 of 1549, perplexity: 67.780 speed: 984 wps\n",
      "Itr 1242 of 1549, perplexity: 67.007 speed: 983 wps\n",
      "Itr 1396 of 1549, perplexity: 65.416 speed: 984 wps\n",
      "Epoch 7 : Train Perplexity: 64.401\n",
      "Epoch 7 : Valid Perplexity: 122.937\n",
      "Epoch 8 : Learning rate: 0.125\n",
      "Itr 10 of 1549, perplexity: 75.291 speed: 1022 wps\n",
      "Itr 164 of 1549, perplexity: 71.500 speed: 970 wps\n",
      "Itr 318 of 1549, perplexity: 69.792 speed: 975 wps\n",
      "Itr 472 of 1549, perplexity: 67.253 speed: 972 wps\n",
      "Itr 626 of 1549, perplexity: 64.322 speed: 979 wps\n",
      "Itr 780 of 1549, perplexity: 63.576 speed: 980 wps\n",
      "Itr 934 of 1549, perplexity: 62.550 speed: 979 wps\n",
      "Itr 1088 of 1549, perplexity: 61.587 speed: 987 wps\n",
      "Itr 1242 of 1549, perplexity: 60.819 speed: 991 wps\n",
      "Itr 1396 of 1549, perplexity: 59.308 speed: 994 wps\n",
      "Epoch 8 : Train Perplexity: 58.326\n",
      "Epoch 8 : Valid Perplexity: 122.612\n",
      "Epoch 9 : Learning rate: 0.062\n",
      "Itr 10 of 1549, perplexity: 71.119 speed: 1028 wps\n",
      "Itr 164 of 1549, perplexity: 67.876 speed: 1027 wps\n",
      "Itr 318 of 1549, perplexity: 66.250 speed: 1017 wps\n",
      "Itr 472 of 1549, perplexity: 63.852 speed: 1019 wps\n",
      "Itr 626 of 1549, perplexity: 61.013 speed: 1021 wps\n",
      "Itr 780 of 1549, perplexity: 60.294 speed: 1022 wps\n",
      "Itr 934 of 1549, perplexity: 59.313 speed: 1019 wps\n",
      "Itr 1088 of 1549, perplexity: 58.369 speed: 1019 wps\n",
      "Itr 1242 of 1549, perplexity: 57.603 speed: 1020 wps\n",
      "Itr 1396 of 1549, perplexity: 56.142 speed: 1020 wps\n",
      "Epoch 9 : Train Perplexity: 55.183\n",
      "Epoch 9 : Valid Perplexity: 122.526\n",
      "Epoch 10 : Learning rate: 0.031\n",
      "Itr 10 of 1549, perplexity: 68.859 speed: 1002 wps\n",
      "Itr 164 of 1549, perplexity: 65.885 speed: 1012 wps\n",
      "Itr 318 of 1549, perplexity: 64.323 speed: 1019 wps\n",
      "Itr 472 of 1549, perplexity: 62.008 speed: 1016 wps\n",
      "Itr 626 of 1549, perplexity: 59.240 speed: 1012 wps\n",
      "Itr 780 of 1549, perplexity: 58.539 speed: 1011 wps\n",
      "Itr 934 of 1549, perplexity: 57.592 speed: 1014 wps\n",
      "Itr 1088 of 1549, perplexity: 56.657 speed: 1011 wps\n",
      "Itr 1242 of 1549, perplexity: 55.891 speed: 1014 wps\n",
      "Itr 1396 of 1549, perplexity: 54.459 speed: 1015 wps\n",
      "Epoch 10 : Train Perplexity: 53.513\n",
      "Epoch 10 : Valid Perplexity: 122.435\n",
      "Epoch 11 : Learning rate: 0.016\n",
      "Itr 10 of 1549, perplexity: 67.539 speed: 1027 wps\n",
      "Itr 164 of 1549, perplexity: 64.801 speed: 1027 wps\n",
      "Itr 318 of 1549, perplexity: 63.261 speed: 1033 wps\n",
      "Itr 472 of 1549, perplexity: 60.993 speed: 1028 wps\n",
      "Itr 626 of 1549, perplexity: 58.267 speed: 1028 wps\n",
      "Itr 780 of 1549, perplexity: 57.580 speed: 1027 wps\n",
      "Itr 934 of 1549, perplexity: 56.653 speed: 1028 wps\n",
      "Itr 1088 of 1549, perplexity: 55.727 speed: 1024 wps\n",
      "Itr 1242 of 1549, perplexity: 54.965 speed: 1019 wps\n",
      "Itr 1396 of 1549, perplexity: 53.549 speed: 1015 wps\n",
      "Epoch 11 : Train Perplexity: 52.609\n",
      "Epoch 11 : Valid Perplexity: 122.251\n",
      "Epoch 12 : Learning rate: 0.008\n",
      "Itr 10 of 1549, perplexity: 66.771 speed: 1033 wps\n",
      "Itr 164 of 1549, perplexity: 64.204 speed: 1021 wps\n",
      "Itr 318 of 1549, perplexity: 62.672 speed: 1011 wps\n",
      "Itr 472 of 1549, perplexity: 60.434 speed: 1014 wps\n",
      "Itr 626 of 1549, perplexity: 57.738 speed: 1017 wps\n",
      "Itr 780 of 1549, perplexity: 57.057 speed: 1019 wps\n",
      "Itr 934 of 1549, perplexity: 56.141 speed: 1018 wps\n",
      "Itr 1088 of 1549, perplexity: 55.222 speed: 1018 wps\n",
      "Itr 1242 of 1549, perplexity: 54.464 speed: 1018 wps\n",
      "Itr 1396 of 1549, perplexity: 53.057 speed: 1019 wps\n",
      "Epoch 12 : Train Perplexity: 52.119\n",
      "Epoch 12 : Valid Perplexity: 122.007\n",
      "Epoch 13 : Learning rate: 0.004\n",
      "Itr 10 of 1549, perplexity: 66.346 speed: 1000 wps\n",
      "Itr 164 of 1549, perplexity: 63.873 speed: 946 wps\n",
      "Itr 318 of 1549, perplexity: 62.346 speed: 960 wps\n",
      "Itr 472 of 1549, perplexity: 60.125 speed: 978 wps\n",
      "Itr 626 of 1549, perplexity: 57.448 speed: 990 wps\n",
      "Itr 780 of 1549, perplexity: 56.769 speed: 986 wps\n",
      "Itr 934 of 1549, perplexity: 55.863 speed: 984 wps\n",
      "Itr 1088 of 1549, perplexity: 54.948 speed: 985 wps\n",
      "Itr 1242 of 1549, perplexity: 54.191 speed: 985 wps\n",
      "Itr 1396 of 1549, perplexity: 52.789 speed: 987 wps\n",
      "Epoch 13 : Train Perplexity: 51.854\n",
      "Epoch 13 : Valid Perplexity: 121.794\n",
      "Epoch 14 : Learning rate: 0.002\n",
      "Itr 10 of 1549, perplexity: 66.116 speed: 956 wps\n",
      "Itr 164 of 1549, perplexity: 63.685 speed: 944 wps\n",
      "Itr 318 of 1549, perplexity: 62.168 speed: 978 wps\n",
      "Itr 472 of 1549, perplexity: 59.957 speed: 984 wps\n",
      "Itr 626 of 1549, perplexity: 57.289 speed: 984 wps\n",
      "Itr 780 of 1549, perplexity: 56.613 speed: 967 wps\n",
      "Itr 934 of 1549, perplexity: 55.712 speed: 962 wps\n",
      "Itr 1088 of 1549, perplexity: 54.800 speed: 965 wps\n",
      "Itr 1242 of 1549, perplexity: 54.044 speed: 970 wps\n",
      "Itr 1396 of 1549, perplexity: 52.644 speed: 969 wps\n",
      "Epoch 14 : Train Perplexity: 51.711\n",
      "Epoch 14 : Valid Perplexity: 121.654\n",
      "Epoch 15 : Learning rate: 0.001\n",
      "Itr 10 of 1549, perplexity: 65.998 speed: 959 wps\n",
      "Itr 164 of 1549, perplexity: 63.582 speed: 1023 wps\n",
      "Itr 318 of 1549, perplexity: 62.071 speed: 998 wps\n",
      "Itr 472 of 1549, perplexity: 59.866 speed: 963 wps\n",
      "Itr 626 of 1549, perplexity: 57.203 speed: 943 wps\n",
      "Itr 780 of 1549, perplexity: 56.530 speed: 929 wps\n",
      "Itr 934 of 1549, perplexity: 55.632 speed: 923 wps\n",
      "Itr 1088 of 1549, perplexity: 54.722 speed: 915 wps\n",
      "Itr 1242 of 1549, perplexity: 53.965 speed: 909 wps\n",
      "Itr 1396 of 1549, perplexity: 52.568 speed: 907 wps\n",
      "Epoch 15 : Train Perplexity: 51.636\n",
      "Epoch 15 : Valid Perplexity: 121.577\n",
      "Test Perplexity: 117.343\n"
     ]
    }
   ],
   "source": [
    "# Instantiates the PTBModel class\n",
    "m=PTBModel.instance()   \n",
    "K = tf.keras.backend \n",
    "for i in range(max_epoch):\n",
    "    # Define the decay for this epoch\n",
    "    lr_decay = decay ** max(i - max_epoch_decay_lr, 0.0)\n",
    "    dcr = learning_rate * lr_decay\n",
    "    m._lr = dcr\n",
    "    K.set_value(m._model.optimizer.learning_rate,m._lr)\n",
    "    print(\"Epoch %d : Learning rate: %.3f\" % (i + 1, m._model.optimizer.learning_rate))\n",
    "    # Run the loop for this epoch in the training mode\n",
    "    train_perplexity, w_test, w_target = run_one_epoch(m, train_data,is_training=True,verbose=True)\n",
    "    print(\"Epoch %d : Train Perplexity: %.3f\" % (i + 1, train_perplexity))\n",
    "        \n",
    "    # Run the loop for this epoch in the validation mode\n",
    "    valid_perplexity, w_test, w_target = run_one_epoch(m, valid_data,is_training=False,verbose=False)\n",
    "    print(\"Epoch %d : Valid Perplexity: %.3f\" % (i + 1, valid_perplexity))\n",
    "    \n",
    "# Run the loop in the testing mode to see how effective was our training\n",
    "test_perplexity, words_test, words_target = run_one_epoch(m, test_data,is_training=False,verbose=False)\n",
    "print(\"Test Perplexity: %.3f\" % test_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 20)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 20)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['earlier', '<eos>', 'the', 'company', '<unk>', '<unk>', \"n't\", 'N', 'in', 'from', 'N', 'from', 'a', 'N', 'a', 'year', 'earlier', '<eos>', 'the', 'company']\n",
      "['earlier', '<eos>', 'the', '<unk>', 'total', 'was', 'N', 'tons', 'up', 'N', 'N', 'from', 'N', 'tons', 'a', 'year', 'earlier', '<eos>', 'the', 'treasury']\n"
     ]
    }
   ],
   "source": [
    "#Predictions first batch\n",
    "print(id_to_word(words_test[0]))\n",
    "#Target first batch\n",
    "print(id_to_word(words_target[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the model's perplexity rating drops very quickly after a few iterations. As was elaborated before, <b>lower Perplexity means that the model is more certain about its prediction</b>. As such, we can be sure that this model is performing well!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authors' rights\n",
    "\n",
    "Machine Learning with Python course by IBM on Coursera: https://www.coursera.org/learn/machine-learning-with-python/\n",
    "\n",
    "Completed and modified by Mathilde Marie Duville as part of the IBM Artificial Intelligence Engineering Professional Certificate and corresponding IBM badges. Please, follow the subsequent links to confirm the accreditation:\n",
    "\n",
    "https://www.coursera.org/account/accomplishments/professional-cert/KSLW773DAATP?utm_source=link&utm_medium=certificate&utm_content=cert_image&utm_campaign=sharing_cta&utm_product=prof\n",
    "\n",
    "https://www.credly.com/users/mathilde-marie-duville/badges\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Author: <a href=\"https://br.linkedin.com/in/walter-gomes-de-amorim-junior-624726121?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0120ENSkillsNetwork954-2023-01-01\">Walter Gomes de Amorim Junior</a>, <a href = \"https://linkedin.com/in/saeedaghabozorgi\"> Saeed Aghabozorgi </a></h4>\n",
    "\n",
    "\n",
    "Updated to TF 2.X by  <a href=\"https://www.linkedin.com/in/samaya-madhavan?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0120ENSkillsNetwork954-2023-01-01\"> Samaya Madhavan </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Copyright &copy; 2018 [Cognitive Class](https://cocl.us/DX0108EN_CC). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0120ENSkillsNetwork954-2023-01-01).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
